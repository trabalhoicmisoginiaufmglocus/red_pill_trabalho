{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673e69ea-581e-40d5-b497-0b6a8617c77e",
   "metadata": {
    "id": "673e69ea-581e-40d5-b497-0b6a8617c77e"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a27765e-167c-4089-9daf-401780f3bc55",
   "metadata": {
    "id": "3a27765e-167c-4089-9daf-401780f3bc55"
   },
   "outputs": [],
   "source": [
    "# Separe aqui seus dados pra fazer a inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fe8a7c-8fd6-4bc7-8aa9-409756fdf2b5",
   "metadata": {
    "id": "16fe8a7c-8fd6-4bc7-8aa9-409756fdf2b5"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "# caminho_base = '/content/drive/MyDrive/red_pill_analises/classificador/oficial_comentarios_classificacao/'\n",
    "caminho_base = ''\n",
    "caminho_folds = os.path.join(caminho_base, 'folds/')\n",
    "\n",
    "# caminho_embeddings = os.path.join(caminho_base, 'videos/embeddings_minilm/')\n",
    "# caminho_resultados = os.path.join(caminho_base, 'videos/resultados_minilm/')\n",
    "\n",
    "caminho_embeddings = os.path.join(caminho_base, 'comentarios/embeddings_qwen_4/')\n",
    "caminho_resultados = os.path.join(caminho_base, 'comentarios/resultados_qwen_4/')\n",
    "\n",
    "# Preciso dos seguintes arquivos: Os 10 arquivos de folds, csv de vizinhos e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d5e72e-2e37-436f-8169-f3d603684203",
   "metadata": {
    "id": "e5d5e72e-2e37-436f-8169-f3d603684203"
   },
   "source": [
    "# Setup Llama 3.1:8b Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7acdd5c-ade8-4253-b5e3-086d4c3c9a91",
   "metadata": {
    "id": "d7acdd5c-ade8-4253-b5e3-086d4c3c9a91"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='llm_inferences.log',\n",
    "    filemode='a'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7264893b-8d1b-40cf-a217-286f73c29d49",
   "metadata": {
    "id": "7264893b-8d1b-40cf-a217-286f73c29d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from /home/jovyan/datalake/models/llama3-8b...\n",
      "pad_token defined as eos_token for tokenizer.\n",
      "Loading model from /home/jovyan/datalake/models/llama3-8b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b1b9ff6807457eb26863b92e86779d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "local_path = \"/home/jovyan/datalake/models/llama3-8b\"\n",
    "\n",
    "print(f\"Loading tokenizer from {local_path}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    local_path,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"pad_token defined as eos_token for tokenizer.\")\n",
    "\n",
    "print(f\"Loading model from {local_path}...\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_path,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True,\n",
    "    dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2626f56-2ac9-47be-948e-c885b7c37131",
   "metadata": {
    "id": "c2626f56-2ac9-47be-948e-c885b7c37131"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702294ef-90ed-4ab5-9bac-bba98793f243",
   "metadata": {
    "id": "702294ef-90ed-4ab5-9bac-bba98793f243"
   },
   "outputs": [],
   "source": [
    "generation_params = {\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"do_sample\": False,\n",
    "    #\"temperature\": 0.7,\n",
    "    \"truncation\": False,\n",
    "    \"return_full_text\": False,\n",
    "}\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "410239a6-5ec1-4639-9549-53399ce2db29",
   "metadata": {
    "id": "410239a6-5ec1-4639-9549-53399ce2db29"
   },
   "outputs": [],
   "source": [
    "def save_batch_to_csv(batch, results_to_save):\n",
    "    \"\"\"\n",
    "    Save a batch result into a CSV file, creating the header if the file\n",
    "    does not exist or is empty.\n",
    "\n",
    "    Args:\n",
    "        batch (int): Batch ID\n",
    "        results_to_save (list): List of llm results obtained (prompt + output)\n",
    "    \"\"\"\n",
    "\n",
    "    output_csv_file = f\"llm_inferences/llama3.1-8b-instruct/{batch}.csv\"\n",
    "    fieldnames = [\"original_id\", \"original_prompt\", \"llm_response\"]\n",
    "\n",
    "    output_dir = Path(output_csv_file).parent\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    write_header = not os.path.exists(output_csv_file) or os.path.getsize(output_csv_file) == 0\n",
    "\n",
    "    try:\n",
    "        with open(output_csv_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            if write_header:\n",
    "                writer.writeheader()\n",
    "                logging.info(f\"Header written to '{output_csv_file}'.\")\n",
    "\n",
    "            writer.writerows(results_to_save)\n",
    "\n",
    "    except IOError as e:\n",
    "        logging.error(f\"Error on saving batch to CSV '{output_csv_file}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76fe421-7188-4515-91cc-b7f9ca0af43a",
   "metadata": {
    "id": "b76fe421-7188-4515-91cc-b7f9ca0af43a"
   },
   "outputs": [],
   "source": [
    "PROGRESS_FILE = 'inferences.json'\n",
    "\n",
    "def load_progress():\n",
    "    \"\"\"Load the progress from a JSON file.\"\"\"\n",
    "    if os.path.exists(PROGRESS_FILE):\n",
    "        with open(PROGRESS_FILE, 'r') as f:\n",
    "            logging.info(f\"Progress file '{PROGRESS_FILE}' found. Loading state.\")\n",
    "            return json.load(f)\n",
    "    logging.info(f\"No progress file '{PROGRESS_FILE}' found. Starting from zero.\")\n",
    "    return {}\n",
    "\n",
    "def save_progress(progress_data):\n",
    "    \"\"\"Save the current progress into a JSON file\"\"\"\n",
    "    with open(PROGRESS_FILE, 'w') as f:\n",
    "        json.dump(progress_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc7e7108-f1fb-445d-89eb-a022110ec9b6",
   "metadata": {
    "id": "bc7e7108-f1fb-445d-89eb-a022110ec9b6"
   },
   "outputs": [],
   "source": [
    "progress = load_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdLHR9beNnqb",
   "metadata": {
    "id": "fdLHR9beNnqb"
   },
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "214c239e-65f4-42b0-91b5-bc715cb00dfa",
   "metadata": {
    "id": "214c239e-65f4-42b0-91b5-bc715cb00dfa"
   },
   "outputs": [],
   "source": [
    "all_tests = [\n",
    "    # --- Teste 1: Zero-Shot, Português, Sem Conceito ---\n",
    "    {\n",
    "        \"name\": \"teste1_pt_sem_conceito\",\n",
    "        \"system_prompt_base\": (\n",
    "            \"Você é um classificador de texto altamente preciso de comentários do Youtube. \"\n",
    "            \"Sua única função é analisar o comentário do usuário e responder estritamente com '0' ou '1'.\\n\"\n",
    "            \"A pergunta que você deve responder é: O texto é {task_definition}?\"\n",
    "            \"1: O texto É {task_definition}\\n\"\n",
    "            \"0: O texto NÃO é {task_definition}\\n\"\n",
    "            \"Não forneça nenhuma explicação, apenas o número.\"\n",
    "        ),\n",
    "        \"task_definitions\": {\n",
    "            \"toxicidade\": \"TÓXICO\",\n",
    "            \"misoginia\": \"MISÓGINO\"\n",
    "        },\n",
    "        \"few_shot_config\": {\n",
    "            \"toxicidade\": {\"output_prefix\": \"results_toxic\"},\n",
    "            \"misoginia\": {\"output_prefix\": \"results_mysogyny\"}\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # --- Teste 2: Zero-Shot, Inglês, Sem Conceito ---\n",
    "    {\n",
    "        \"name\": \"teste2_en_sem_conceito\",\n",
    "        \"system_prompt_base\": (\n",
    "            \"You are a highly accurate text classifier for Youtube comments. \"\n",
    "            \"Your sole function is to analyze the user's comment and respond strictly with '0' or '1'.\\n\"\n",
    "            \"The question you must answer is: Is the text {task_definition}?\\n\"\n",
    "            \"1: The text IS {task_definition}\\n\"\n",
    "            \"0: The text is NOT {task_definition}\\n\"\n",
    "            \"Do not provide any explanation, just the number.\"\n",
    "        ),\n",
    "        \"task_definitions\": {\n",
    "            \"toxicidade\": \"TOXIC\",\n",
    "            \"misoginia\": \"MISOGYNISTIC\"\n",
    "        },\n",
    "        \"few_shot_config\": {\n",
    "            \"toxicidade\": {\"output_prefix\": \"results_toxic\"},\n",
    "            \"misoginia\": {\"output_prefix\": \"results_mysogyny\"}\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # --- Teste 3: Zero-Shot, Português, Com Conceito ---\n",
    "    {\n",
    "        \"name\": \"teste3_pt_com_conceito\",\n",
    "        \"system_prompt_base\": (\n",
    "            \"Você é um classificador de texto altamente preciso de comentários do Youtube. \"\n",
    "            \"Sua única função é analisar o comentário do usuário e responder estritamente com '0' ou '1'.\\n\"\n",
    "            \"Você deve analisar se o texto contém {task_definition}. Assim, responda:\"\n",
    "            \"1: Se o texto se encaixa em qualquer uma das categorias de conceito listadas \\n\"\n",
    "            \"0: Se o texto NÃO se encaixa em qualquer uma das categorias de conceito listadas\\n\"\n",
    "            \"Não forneça nenhuma explicação, apenas o número.\"\n",
    "        ),\n",
    "        \"task_definitions\": {\n",
    "            \"toxicidade\": \"TOXICIDADE - Utilize as seguintes definições para guiar sua classificação: \\n1. Ódio e Assédio:\\n1.1 Doxing: Divulgação de informações pessoais de um alvo para o público em geral, com o objetivo de prejudicá-lo.\\n1.2 Ataque à identidade: Consiste em ataques severos a indivíduos ou grupos com base em sua afiliação a um grupo protegido ou vulnerável.\\n1.3 Falsa representação de identidade: É a disseminação de declarações que comunicam deturpações pejorativas, estereótipos e outras generalizações insultuosas sobre populações protegidas ou vulneráveis.\\n1.4 Insulto: Ataque pessoal direcionado, como xingamentos, comentários negativos, depreciativos e inflamatórios sobre o indivíduo.\\n1.5 Agressão Sexual: Inclui avanços sexuais indesejados, sexualização indesejável e compartilhamento não consensual de conteúdo sexual, entre outras formas de conversas sexuais não solicitadas.\\n1.6 Ameaça de Violência: Refere-se a conteúdo que expressa o desejo de matar ou infligir dano físico, celebra atos violentos ou incita outros a cometerem violência.\\n2. Dano autoinfligido:\\n2.1 Promoção de transtorno alimentar: Abrange conteúdo que promove transtornos alimentares como escolhas de estilo de vida legítimas ou glorifica corpos excessivamente magros.\\n2.2 Autolesão: Ideação de se machucar fisicamente de propósito para lidar com o sofrimento emocional, incluindo também a ideação suicida.\\n3. Dano ideológico:\\n3.1 Extremismo, terrorismo e crime organizado: Inclui conteúdo relacionado ao recrutamento, elogio ou assistência a grupos extremistas, terroristas ou de crime organizado.\\n3.2 Desinformação: É a informação falsa ou enganosa, que pode ser disseminada com ou sem a intenção deliberada de prejudicar.\\n4. Exploração:\\n4.1 Serviços sexuais adultos: Refere-se à promoção ou solicitação de serviços sexuais ilegais que exploram participantes frequentemente vulneráveis.\\n4.2 Material de abuso sexual infantil: É definido como conteúdo que envolve o abuso e a exploração sexual de qualquer pessoa menor de dezoito anos.\\n4.3 Golpes: São tentativas de enganar uma pessoa para que ela forneça fundos ou informações sensíveis usando técnicas fraudulentas ou invasivas.\\n\",\n",
    "            \"misoginia\": \"MISOGINIA - Utilize as seguintes definições para guiar sua classificação: \\n1. Ameaças, planos para prejudicar e incitamento:\\n1.1 Ameaças de danos: Expressar desejo de prejudicar física, sexual ou emocionalmente uma mulher ou grupo de mulheres.\\n1.2 Incitamento e incentivo ao dano: Encorajar ou justificar que outros prejudiquem uma mulher ou grupo de mulheres.\\n2. Depreciação:\\n2.1 Ataques descritivos: Fazer generalizações negativas sobre as habilidades, aparência, intelecto ou caráter das mulheres.\\n2.2 Ataques agressivos e emotivos: Expressar ódio ou nojo contra as mulheres, usando insultos de gênero ou acusações infundadas.\\n2.3 Ataques desumanizantes e objetificação sexual explícita: Comparar mulheres a animais/objetos ou reduzi-las a objetos sexuais.\\n3. Animosidade:\\n3.1 Uso casual de gírias de gênero, profanidades e insultos: Usar termos pejorativos para mulheres de forma casual, não como um ataque direto.\\n3.2 Diferenças imutáveis de gênero e estereótipos de gênero: Afirmar diferenças 'naturais' entre homens e mulheres para implicar inferioridade ou limitar papéis (inclui a maioria das piadas sexistas).\\n3.3 Elogios de gênero ambíguos: Elogiar mulheres de forma que reforce estereótipos de fragilidade, ou que reduza seu valor à sua atratividade.\\n3.4 Explicações condescendentes ou conselhos indesejados: Oferecer conselhos paternalistas a mulheres sobre assuntos que elas dominam ('mansplaining').\\n4. Discussão Preconceituosa:\\n4.1 Apoio ao mau tratamento de mulheres individuais: Justificar, negar ou subestimar o mau tratamento de uma mulher.\\n4.2 Apoio à discriminação sistêmica contra mulheres como grupo: Justificar, negar ou subestimar a discriminação contra as mulheres como um grupo.\\n\"\n",
    "        },\n",
    "        \"few_shot_config\": {\n",
    "            \"toxicidade\": {\"output_prefix\": \"results_toxic\"},\n",
    "            \"misoginia\": {\"output_prefix\": \"results_mysogyny\"}\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # --- Teste 4: Zero-Shot, Inglês, Com Conceito ---\n",
    "    {\n",
    "        \"name\": \"teste4_en_com_conceito\",\n",
    "        \"system_prompt_base\": (\n",
    "            \"You are a highly accurate text classifier for Youtube comments. \"\n",
    "            \"Your sole function is to analyze the user's comment and respond strictly with '0' or '1'.\\n\"\n",
    "            \"You must analyze if the text contains {task_definition}. Accordingly, respond:\\n\"\n",
    "            \"1: If the text fits into any of the listed concept categories\\n\"\n",
    "            \"0: If the text does NOT fit into any of the listed concept categories\\n\"\n",
    "            \"Do not provide any explanation, just the number.\"\n",
    "        ),\n",
    "        \"task_definitions\": {\n",
    "            \"toxicidade\": \"TOXICITY - Use the following definitions to guide your classification: \\n1. Hate and Harassment:\\n1.1 Doxing: Disclosure of a target's personal information to the general public with the intent to harm them.\\n1.2 Identity Attack: Consists of severe attacks on individuals or groups based on their affiliation with a protected or vulnerable group.\\n1.3 Misrepresentation of Identity: Is the dissemination of statements that communicate pejorative misrepresentations, stereotypes, and other insulting generalizations about protected or vulnerable populations.\\n1.4 Insult: A directed personal attack, such as name-calling, negative, derogatory, and inflammatory comments about the individual.\\n1.5 Sexual Aggression: Includes unwanted sexual advances, unwelcome sexualization, and non-consensual sharing of sexual content, among other forms of unsolicited sexual conversations.\\n1.6 Threat of Violence: Refers to content that expresses the desire to kill or inflict physical harm, celebrates violent acts, or incites others to commit violence.\\n2. Self-Harm:\\n2.1 Promotion of Eating Disorders: Covers content that promotes eating disorders as legitimate lifestyle choices or glorifies excessively thin bodies.\\n2.2 Self-Injury: Ideation of purposely physically hurting oneself to cope with emotional distress, including suicidal ideation.\\n3. Ideological Harm:\\n3.1 Extremism, Terrorism, and Organized Crime: Includes content related to the recruitment, praise, or assistance of extremist, terrorist, or organized crime groups.\\n3.2 Disinformation: Is false or misleading information, which can be disseminated with or without the deliberate intention to cause harm.\\n4. Exploitation:\\n4.1 Adult Sexual Services: Refers to the promotion or solicitation of illegal sexual services that exploit often-vulnerable participants.\\n4.2 Child Sexual Abuse Material: Is defined as content that involves the sexual abuse and exploitation of any person under the age of eighteen.\\n4.3 Scams: Are attempts to deceive a person into providing funds or sensitive information using fraudulent or invasive techniques.\\n\",\n",
    "            \"misoginia\": \"MISOGYNY - Use the following definitions to guide your classification: \\n1. Threats, plans to harm, and incitement:\\n1.1 Threats of harm: Expressing a desire to physically, sexually, or emotionally harm a woman or group of women.\\n1.2 Incitement and encouragement of harm: Encouraging or justifying others to harm a woman or group of women.\\n2. Derogation:\\n2.1 Descriptive attacks: Making negative generalizations about women's skills, appearance, intellect, or character.\\n2.2 Aggressive and emotive attacks: Expressing hatred or disgust against women, using gendered slurs or baseless accusations.\\n2.3 Dehumanizing attacks and explicit sexual objectification: Comparing women to animals/objects or reducing them to sexual objects.\\n3. Animosity:\\n3.1 Casual use of gendered slurs, profanity, and insults: Using derogatory terms for women casually, not as a direct attack.\\n3.2 Immutable gender differences and gender stereotypes: Asserting 'natural' differences between men and women to imply inferiority or limit roles (includes most sexist jokes).\\n3.3 Ambiguous gendered praise: Praising women in a way that reinforces stereotypes of fragility, or that reduces their value to their attractiveness.\\n3.4 Condescending explanations or unsolicited advice: Offering paternalistic advice to women on subjects they are knowledgeable about ('mansplaining').\\n4. Prejudiced Discussion:\\n4.1 Support for the mistreatment of individual women: Justifying, denying, or understating the mistreatment of a woman.\\n4.2 Support for systemic discrimination against women as a group: Justifying, denying, or understating discrimination against women as a group.\\n\"\n",
    "        },\n",
    "        \"few_shot_config\": {\n",
    "            \"toxicidade\": {\"output_prefix\": \"results_toxic\"},\n",
    "            \"misoginia\": {\"output_prefix\": \"results_mysogyny\"}\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3i-3LdcMAg_o",
   "metadata": {
    "id": "3i-3LdcMAg_o"
   },
   "source": [
    "# Código: Few Shot COM EMBEDDINGS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "l6C4vcSc3RLD",
   "metadata": {
    "id": "l6C4vcSc3RLD",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "teste1_pt_sem_conceito - F1 (toxicidade): 100%|██████████| 7/7 [00:43<00:00,  6.28s/it]\n",
      "teste1_pt_sem_conceito - F1 (misoginia): 100%|██████████| 7/7 [00:35<00:00,  5.10s/it]\n",
      "teste1_pt_sem_conceito - F2 (toxicidade): 100%|██████████| 7/7 [00:39<00:00,  5.69s/it]\n",
      "teste1_pt_sem_conceito - F2 (misoginia): 100%|██████████| 7/7 [00:49<00:00,  7.03s/it]\n",
      "teste1_pt_sem_conceito - F3 (toxicidade): 100%|██████████| 7/7 [00:48<00:00,  6.99s/it]\n",
      "teste1_pt_sem_conceito - F3 (misoginia): 100%|██████████| 7/7 [00:47<00:00,  6.71s/it]\n",
      "teste1_pt_sem_conceito - F4 (toxicidade): 100%|██████████| 7/7 [00:39<00:00,  5.66s/it]\n",
      "teste1_pt_sem_conceito - F4 (misoginia): 100%|██████████| 7/7 [00:46<00:00,  6.70s/it]\n",
      "teste1_pt_sem_conceito - F5 (toxicidade): 100%|██████████| 7/7 [00:37<00:00,  5.31s/it]\n",
      "teste1_pt_sem_conceito - F5 (misoginia): 100%|██████████| 7/7 [00:45<00:00,  6.46s/it]\n",
      "teste2_en_sem_conceito - F1 (toxicidade): 100%|██████████| 7/7 [00:47<00:00,  6.73s/it]\n",
      "teste2_en_sem_conceito - F1 (misoginia): 100%|██████████| 7/7 [00:35<00:00,  5.11s/it]\n",
      "teste2_en_sem_conceito - F2 (toxicidade): 100%|██████████| 7/7 [00:38<00:00,  5.52s/it]\n",
      "teste2_en_sem_conceito - F2 (misoginia): 100%|██████████| 7/7 [00:47<00:00,  6.82s/it]\n",
      "teste2_en_sem_conceito - F3 (toxicidade): 100%|██████████| 7/7 [00:46<00:00,  6.68s/it]\n",
      "teste2_en_sem_conceito - F3 (misoginia): 100%|██████████| 7/7 [00:45<00:00,  6.46s/it]\n",
      "teste2_en_sem_conceito - F4 (toxicidade): 100%|██████████| 7/7 [00:37<00:00,  5.32s/it]\n",
      "teste2_en_sem_conceito - F4 (misoginia): 100%|██████████| 7/7 [00:44<00:00,  6.38s/it]\n",
      "teste2_en_sem_conceito - F5 (toxicidade): 100%|██████████| 7/7 [00:34<00:00,  4.99s/it]\n",
      "teste2_en_sem_conceito - F5 (misoginia): 100%|██████████| 7/7 [00:43<00:00,  6.16s/it]\n",
      "teste3_pt_com_conceito - F1 (toxicidade): 100%|██████████| 7/7 [01:31<00:00, 13.03s/it]\n",
      "teste3_pt_com_conceito - F1 (misoginia): 100%|██████████| 7/7 [01:10<00:00, 10.11s/it]\n",
      "teste3_pt_com_conceito - F2 (toxicidade): 100%|██████████| 7/7 [01:22<00:00, 11.80s/it]\n",
      "teste3_pt_com_conceito - F2 (misoginia): 100%|██████████| 7/7 [01:23<00:00, 11.96s/it]\n",
      "teste3_pt_com_conceito - F3 (toxicidade): 100%|██████████| 7/7 [01:30<00:00, 12.99s/it]\n",
      "teste3_pt_com_conceito - F3 (misoginia): 100%|██████████| 7/7 [01:21<00:00, 11.59s/it]\n",
      "teste3_pt_com_conceito - F4 (toxicidade): 100%|██████████| 7/7 [01:20<00:00, 11.52s/it]\n",
      "teste3_pt_com_conceito - F4 (misoginia): 100%|██████████| 7/7 [01:20<00:00, 11.53s/it]\n",
      "teste3_pt_com_conceito - F5 (toxicidade): 100%|██████████| 7/7 [01:18<00:00, 11.15s/it]\n",
      "teste3_pt_com_conceito - F5 (misoginia): 100%|██████████| 7/7 [01:19<00:00, 11.31s/it]\n",
      "teste4_en_com_conceito - F1 (toxicidade): 100%|██████████| 7/7 [01:14<00:00, 10.64s/it]\n",
      "teste4_en_com_conceito - F1 (misoginia): 100%|██████████| 7/7 [00:59<00:00,  8.49s/it]\n",
      "teste4_en_com_conceito - F2 (toxicidade): 100%|██████████| 7/7 [01:05<00:00,  9.33s/it]\n",
      "teste4_en_com_conceito - F2 (misoginia): 100%|██████████| 7/7 [01:11<00:00, 10.19s/it]\n",
      "teste4_en_com_conceito - F3 (toxicidade): 100%|██████████| 7/7 [01:14<00:00, 10.59s/it]\n",
      "teste4_en_com_conceito - F3 (misoginia): 100%|██████████| 7/7 [01:08<00:00,  9.84s/it]\n",
      "teste4_en_com_conceito - F4 (toxicidade): 100%|██████████| 7/7 [01:04<00:00,  9.26s/it]\n",
      "teste4_en_com_conceito - F4 (misoginia): 100%|██████████| 7/7 [01:08<00:00,  9.79s/it]\n",
      "teste4_en_com_conceito - F5 (toxicidade): 100%|██████████| 7/7 [01:02<00:00,  8.92s/it]\n",
      "teste4_en_com_conceito - F5 (misoginia): 100%|██████████| 7/7 [01:06<00:00,  9.53s/it]\n"
     ]
    }
   ],
   "source": [
    "# Para rodar para todos de 1 só vez\n",
    "import pandas as pd\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "import os\n",
    "\n",
    "# --- Configurações Iniciais ---\n",
    "# Tamanho do lote para a pipeline do LLM (quantos prompts enviar para a GPU de uma vez)\n",
    "LLM_BATCH_SIZE = 64 #\n",
    "transformers.logging.set_verbosity_error()\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', filename='processamento_llm_dynamic.log', filemode='w')\n",
    "\n",
    "# =========================================================\n",
    "# PARTE 1: CARREGAMENTO MESTRE DE TODOS OS COMENTÁRIOS\n",
    "# =========================================================\n",
    "# Vamos carregar todos os 10 folds em memória UMA VEZ para\n",
    "# criar um \"banco de dados\" (lookup) de id_comentario -> texto.\n",
    "# Isso é MUITO mais rápido do que ler arquivos dentro do loop.\n",
    "\n",
    "logging.info(\"Carregando todos os 10 dataframes de folds para lookup...\")\n",
    "master_lookups = {} # Dicionário para guardar os DFs mestres\n",
    "\n",
    "try:\n",
    "    for task_key in ['toxicidade', 'misoginia']:\n",
    "        sufixo = \"_TOXICIDADE\" if task_key == 'toxicidade' else \"_MISOGINIA\"\n",
    "        label_col = 'final_toxicidade' if task_key == 'toxicidade' else 'final_misoginia'\n",
    "\n",
    "        all_dfs = []\n",
    "        for i in range(1, 6):\n",
    "            # Assumindo que os arquivos estão na mesma pasta, como você mencionou\n",
    "            fname = f\"comentarios_fold_{i}_estratificado{sufixo}.csv\"\n",
    "            all_dfs.append(pd.read_csv(os.path.join(caminho_folds, fname)))\n",
    "\n",
    "        # Concatena os 5 folds da tarefa em um único DataFrame\n",
    "        df_master = pd.concat(all_dfs)\n",
    "\n",
    "        # Define o ID como índice para buscas O(1) (super rápidas)\n",
    "        # E seleciona apenas as colunas que importam\n",
    "        master_lookups[task_key] = df_master[['id_comentario_anonimizado', 'comentario', label_col]].set_index('id_comentario_anonimizado')\n",
    "\n",
    "        logging.info(f\"Lookup mestre para '{task_key}' criado com {len(master_lookups[task_key])} vídeos.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(f\"Erro fatal: Não foi possível carregar os arquivos de fold. Verifique se todos os 10 CSVs (videos_fold_...csv) estão na pasta. Arquivo faltando: {e.filename}\")\n",
    "    raise e\n",
    "\n",
    "logging.info(\"Carregamento mestre de todos os folds concluído.\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# PARTE 2: LOOP DE PROCESSAMENTO DINÂMICO\n",
    "# =========================================================\n",
    "\n",
    "for test_config in all_tests:\n",
    "    test_name = test_config[\"name\"]\n",
    "    SYSTEM_PROMPT_BASE = test_config[\"system_prompt_base\"]\n",
    "    TASK_DEFINITIONS = test_config[\"task_definitions\"]\n",
    "    FEW_SHOT_CONFIG = test_config[\"few_shot_config\"]\n",
    "\n",
    "    logging.info(f\"############################################################\")\n",
    "    logging.info(f\"##### INICIANDO GRUPO DE TESTE: {test_name} #####\")\n",
    "    logging.info(f\"############################################################\")\n",
    "\n",
    "    for fold_number in range(1, 6):\n",
    "        for task_name_pt, config in FEW_SHOT_CONFIG.items():\n",
    "\n",
    "            task_key = 'misoginia' if task_name_pt == 'misoginia' else 'toxicidade'\n",
    "            label_column = 'final_misoginia' if task_key == 'misoginia' else 'final_toxicidade'\n",
    "            sufixo_arquivo = \"_MISOGINIA\" if task_key == 'misoginia' else \"_TOXICIDADE\"\n",
    "\n",
    "            logging.info(f\"============================================================\")\n",
    "            logging.info(f\"PROCESSANDO: Teste '{test_name}' - Fold {fold_number} - Tarefa: {task_key}\")\n",
    "            logging.info(f\"============================================================\")\n",
    "\n",
    "            # --- 1. Definir arquivos de entrada para este loop ---\n",
    "            # Arquivo com a lista de comentários a processar (o fold de teste)\n",
    "            test_list_filename = f\"comentarios_fold_{fold_number}_estratificado{sufixo_arquivo}.csv\"\n",
    "            # Arquivo com os vizinhos para CADA comentário de teste\n",
    "            neighbor_filename = f\"nearest_neighbors_{task_key}_fold_{fold_number}.csv\" # (sem data)\n",
    "\n",
    "            try:\n",
    "                # Carrega a lista de comentários que vamos classificar\n",
    "                df_test_list = pd.read_csv(os.path.join(caminho_folds, test_list_filename))\n",
    "                # Carrega o DF de vizinhos e o indexa por ID para busca rápida\n",
    "                df_neighbors = pd.read_csv(os.path.join(caminho_embeddings, neighbor_filename)).set_index('id_comentario_anonimizado')\n",
    "            except FileNotFoundError as e:\n",
    "                logging.warning(f\"Arquivo não encontrado: {e.filename}. Pulando Fold {fold_number} / Tarefa {task_key}.\")\n",
    "                continue\n",
    "\n",
    "            # Pega o lookup mestre de textos/rótulos que já carregamos\n",
    "            df_master_lookup = master_lookups[task_key]\n",
    "\n",
    "            # --- 2. Preparar Prompt ---\n",
    "            task_definition = TASK_DEFINITIONS.get(task_key, \"\")\n",
    "            dynamic_system_prompt = SYSTEM_PROMPT_BASE.format(task_definition=task_definition)\n",
    "            prefix = \"Comment:\" if 'en' in test_name else \"Comentário:\"\n",
    "\n",
    "            # --- 3. Loop de Processamento (em Lotes) ---\n",
    "            all_results_for_run = []\n",
    "\n",
    "            # Itera sobre o DataFrame de TESTE em lotes (para a pipeline do LLM)\n",
    "            for start in tqdm(range(0, len(df_test_list), LLM_BATCH_SIZE), desc=f\"{test_name} - F{fold_number} ({task_key})\"):\n",
    "                end = start + LLM_BATCH_SIZE\n",
    "                chunk_df = df_test_list.iloc[start:end]\n",
    "\n",
    "                batch_conversations = [] # Lista de prompts (conversas) para o lote\n",
    "                batch_original_data = [] # Lista para guardar IDs e textos originais\n",
    "\n",
    "                # --- 3a. Construir os prompts dinâmicos para o lote ---\n",
    "                for _, row in chunk_df.iterrows():\n",
    "                    comment_id = row['id_comentario_anonimizado']\n",
    "                    comment_text = row['comentario']\n",
    "\n",
    "                    try:\n",
    "                        # Pega a linha de vizinhos para este comentário específico\n",
    "                        neighbor_ids = df_neighbors.loc[comment_id]\n",
    "                    except KeyError:\n",
    "                        logging.warning(f\"ID {comment_id} não encontrado no arquivo de vizinhos {neighbor_filename}. Pulando este comentário.\")\n",
    "                        continue\n",
    "\n",
    "                    # Inicia a conversa com o prompt do sistema\n",
    "                    conversation = [{\"role\": \"system\", \"content\": dynamic_system_prompt}]\n",
    "\n",
    "                    # Constrói os exemplos (2 neg, 3 pos)\n",
    "                    examples_to_add = []\n",
    "                    try:\n",
    "                        # 2 Exemplos Negativos (Rótulo 0)\n",
    "                        for i in range(1, 3): # neg_1_id, neg_2_id\n",
    "                            neg_id = neighbor_ids[f'neg_{i}_id']\n",
    "                            neg_text = df_master_lookup.loc[neg_id]['comentario']\n",
    "                            examples_to_add.append({\"role\": \"user\", \"content\": f\"{prefix} '{neg_text}'\"})\n",
    "                            examples_to_add.append({\"role\": \"assistant\", \"content\": \"0\"})\n",
    "\n",
    "                        # 3 Exemplos Positivos (Rótulo 1)\n",
    "                        for i in range(1, 4): # pos_1_id, pos_2_id, pos_3_id\n",
    "                            pos_id = neighbor_ids[f'pos_{i}_id']\n",
    "                            pos_text = df_master_lookup.loc[pos_id]['comentario']\n",
    "                            examples_to_add.append({\"role\": \"user\", \"content\": f\"{prefix} '{pos_text}'\"})\n",
    "                            examples_to_add.append({\"role\": \"assistant\", \"content\": \"1\"})\n",
    "\n",
    "                    except KeyError as e:\n",
    "                        logging.error(f\"Erro de lookup de ID: {e}. O vizinho do video {comment_id} não foi encontrado no lookup mestre. Pulando este comentário.\")\n",
    "                        continue\n",
    "\n",
    "                    # Adiciona os 5 exemplos de few-shot\n",
    "                    conversation.extend(examples_to_add)\n",
    "\n",
    "                    # Adiciona o prompt final do usuário (o comentário a ser classificado)\n",
    "                    formatted_msg = f\"{prefix} '{comment_text}'\"\n",
    "                    conversation.append({\"role\": \"user\", \"content\": formatted_msg})\n",
    "\n",
    "                    # Adiciona a conversa completa ao lote\n",
    "                    batch_conversations.append(conversation)\n",
    "                    # Guarda os dados originais para salvar depois\n",
    "                    batch_original_data.append({\n",
    "                        \"id\": comment_id,\n",
    "                        \"text\": comment_text\n",
    "                    })\n",
    "\n",
    "                if not batch_conversations:\n",
    "                    continue\n",
    "\n",
    "                # --- 3b. Executar a pipeline do LLM no lote ---\n",
    "                batch_prompts_formatted = tokenizer.apply_chat_template(\n",
    "                    batch_conversations, tokenize=False, add_generation_prompt=True\n",
    "                )\n",
    "                batch_results = pipe(batch_prompts_formatted, **generation_params)\n",
    "\n",
    "                # --- 3c. Coletar resultados do lote ---\n",
    "                results_to_save_this_chunk = []\n",
    "                for i, result in enumerate(batch_results):\n",
    "                    llm_response = result[0]['generated_text'].strip()\n",
    "                    original_data = batch_original_data[i]\n",
    "\n",
    "                    results_to_save_this_chunk.append({\n",
    "                        \"original_id\": original_data[\"id\"],\n",
    "                        \"original_prompt\": original_data[\"text\"],\n",
    "                        \"llm_response\": llm_response\n",
    "                    })\n",
    "\n",
    "                if results_to_save_this_chunk:\n",
    "                    all_results_for_run.extend(results_to_save_this_chunk)\n",
    "\n",
    "            # --- 4. Salvar resultados do Fold ---\n",
    "            if all_results_for_run:\n",
    "                output_prefix = config[\"output_prefix\"]\n",
    "                # Nome do arquivo final é dinâmico, baseado nos vizinhos\n",
    "                output_filename = f\"{output_prefix}_{test_name}_fold_{fold_number}_DYNAMIC_NEIGHBORS.csv\"\n",
    "\n",
    "                final_df = pd.DataFrame(all_results_for_run)\n",
    "                final_df.to_csv(os.path.join(caminho_resultados, output_filename), index=False)\n",
    "                logging.info(f\"Resultados (Dinâmicos) salvos em: {output_filename}\")\n",
    "            else:\n",
    "                logging.warning(f\"Nenhum resultado gerado para Teste '{test_name}', Fold {fold_number}, Tarefa: {task_key}\")\n",
    "\n",
    "logging.info(\"============================================================\")\n",
    "logging.info(\"TODOS OS TESTES DINÂMICOS FORAM CONCLUÍDOS!\")\n",
    "logging.info(\"============================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb0c7267-04bd-4c1f-882d-4d7103d590b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oi'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"oi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86d6f2-11e0-4f27-902b-066c76fea1df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "e5d5e72e-2e37-436f-8169-f3d603684203",
    "fdLHR9beNnqb"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
