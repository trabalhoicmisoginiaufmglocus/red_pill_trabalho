{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/VictorHugoMartins/israel_x_palestine_data_analysis/blob/main/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"9qPQErkiUkT1"},"source":["# Experimentos com Modelos de Toxicidade"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7uEayANlWTOd","outputId":"948d4e99-5932-4061-beb6-f8fa9bd96b07","executionInfo":{"status":"ok","timestamp":1763671032702,"user_tz":180,"elapsed":10006,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TAD9WJG2K3C","outputId":"63599c01-410a-44da-f2c9-3d67b892225b","executionInfo":{"status":"ok","timestamp":1763671042988,"user_tz":180,"elapsed":10289,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting detoxify\n","  Downloading detoxify-0.5.2-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from detoxify) (4.57.1)\n","Requirement already satisfied: sentencepiece>=0.1.94 in /usr/local/lib/python3.12/dist-packages (from detoxify) (0.2.1)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (0.36.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->detoxify) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->detoxify) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->detoxify) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->detoxify) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->detoxify) (2025.10.5)\n","Downloading detoxify-0.5.2-py3-none-any.whl (12 kB)\n","Installing collected packages: detoxify\n","Successfully installed detoxify-0.5.2\n"]}],"source":["!pip install detoxify pandas torch"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXwF038J2xke","outputId":"be344f3e-c16d-4116-fcf3-1e40407e825e","executionInfo":{"status":"ok","timestamp":1763671294802,"user_tz":180,"elapsed":251804,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.8.0+cu126\n","Uninstalling torch-2.8.0+cu126:\n","  Successfully uninstalled torch-2.8.0+cu126\n","Found existing installation: torchvision 0.23.0+cu126\n","Uninstalling torchvision-0.23.0+cu126:\n","  Successfully uninstalled torchvision-0.23.0+cu126\n","Found existing installation: torchaudio 2.8.0+cu126\n","Uninstalling torchaudio-2.8.0+cu126:\n","  Successfully uninstalled torchaudio-2.8.0+cu126\n","Looking in indexes: https://download.pytorch.org/whl/cu121\n","Collecting torch\n","  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n","  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==3.1.0 (from torch)\n","  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Collecting sympy==1.13.1 (from torch)\n","  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.4.0\n","    Uninstalling triton-3.4.0:\n","      Successfully uninstalled triton-3.4.0\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.3\n","    Uninstalling sympy-1.13.3:\n","      Successfully uninstalled sympy-1.13.3\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.6.77\n","    Uninstalling nvidia-nvtx-cu12-12.6.77:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.27.3\n","    Uninstalling nvidia-nccl-cu12-2.27.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n","    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"]}],"source":["!pip uninstall -y torch torchvision torchaudio\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121  # Use 'cpu' se não for usar GPU"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"W_tSBfuLKNDK","outputId":"91a28eb4-1011-4b5a-ca7e-4c8562aa62d7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763671303031,"user_tz":180,"elapsed":8223,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"]}],"source":["!pip install scikit-learn"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"XUFJWE8rKNDL","outputId":"4e61ed61-0bae-45e7-8287-4e79b0f017da","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763671311094,"user_tz":180,"elapsed":8055,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"]}],"source":["!pip install torch"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"0Ddpmhh43X-7","executionInfo":{"status":"ok","timestamp":1763671315469,"user_tz":180,"elapsed":4371,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","\n","def plot_ground_truth_por_classe(df_merged, tox_score, label_cols):\n","  df_merged['label_final'] = df_merged[label_cols].mode(axis=1)[0]\n","  print(df_merged['label_final'].value_counts())\n","\n","  return df_merged"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lj2bMnuoraaU","executionInfo":{"status":"ok","timestamp":1763671315479,"user_tz":180,"elapsed":8,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["import pandas as pd\n","\n","def ler_df(folder_path):\n","  df_videos = pd.read_csv(folder_path)\n","  print(\"temos quantos videos? \", len(df_videos))\n","  return df_videos"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"lUTJ9YwR4Hp-","executionInfo":{"status":"ok","timestamp":1763671315990,"user_tz":180,"elapsed":505,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def tabela_anotacao_por_faixa(df_merged, tox_score, min_val=None, max_val=None, n_bins=5):\n","    tox_score = tox_score.strip()\n","\n","    # 1. Resolver colunas duplicadas\n","    col_mask = [col == tox_score for col in df_merged.columns]\n","    col_indices = [i for i, x in enumerate(col_mask) if x]\n","\n","    if len(col_indices) > 1:\n","        print(f\"Coluna duplicada detectada: '{tox_score}' aparece {len(col_indices)} vezes\")\n","        null_counts = [df_merged.iloc[:, i].isnull().sum() for i in col_indices]\n","        best_index = col_indices[np.argmin(null_counts)]\n","        for i in reversed(col_indices):\n","            if i != best_index:\n","                df_merged.drop(columns=df_merged.columns[i], inplace=True)\n","        print(f\"Coluna '{tox_score}' mantida na posição {best_index} com menos nulos\")\n","\n","    if tox_score not in df_merged.columns:\n","        df_merged['tox_sexism_score'] = df_merged['tox_sexism_pred']\n","        tox_score = 'tox_sexism_score'\n","\n","    # 2. Filtrar textos válidos\n","    df_valid = df_merged[df_merged[tox_score].notnull()].copy()\n","\n","    # 3. Ordenar pelo score\n","    df_valid = df_valid.sort_values(by=tox_score).reset_index(drop=True)\n","\n","    total_textos = len(df_valid)\n","    textos_por_faixa = total_textos // n_bins\n","    total_utilizavel = textos_por_faixa * n_bins\n","    df_uniforme = df_valid.iloc[:total_utilizavel].copy()\n","\n","    # 4. Gerar rótulos de intervalo (bins) com base nos scores\n","    min_score = df_uniforme[tox_score].min() if min_val is None else min_val\n","    max_score = df_uniforme[tox_score].max() if max_val is None else max_val\n","    bins = np.linspace(min_score, max_score, n_bins + 1)\n","    faixa_labels = [f'{round(bins[i], 2)}-{round(bins[i+1], 2)}' for i in range(len(bins)-1)]\n","\n","    # 5. Atribuir rótulos com base no índice (não pelo valor do score!)\n","    faixa_indices = np.repeat(faixa_labels, textos_por_faixa)\n","    df_uniforme[\"toxicity_range\"] = faixa_indices\n","\n","    # 6. Agrupar por faixa e contar os labels finais\n","    result = df_uniforme.groupby(['toxicity_range', 'label_final']).size().unstack(fill_value=0)\n","\n","    print(\"Anotação baseada na Moda\")\n","    print(result)\n","\n","    # 7. Plotar as matrizes de confusão por faixa\n","    if 'label_final' in df_uniforme.columns and 'label_pred' in df_uniforme.columns:\n","        confusao_long = df_uniforme.groupby(['toxicity_range', 'label_final', 'label_pred']).size().reset_index(name='count')\n","        confusao_long = confusao_long.rename(columns={'label_final': 'true', 'label_pred': 'pred'})\n","\n","        faixa_order = sorted(df_uniforme['toxicity_range'].unique(), key=lambda x: float(str(x).split('-')[0]))\n","        num_faixas = len(faixa_order)\n","\n","        ncols = 5\n","        nrows = (num_faixas + ncols - 1) // ncols\n","\n","        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5 * ncols, 4 * nrows), constrained_layout=True)\n","        axes = axes.flatten()\n","\n","        for i, faixa in enumerate(faixa_order):\n","            df_faixa = confusao_long[confusao_long['toxicity_range'] == faixa]\n","            pivot_df = df_faixa.pivot(index='true', columns='pred', values='count').fillna(0)\n","\n","            ax = axes[i]\n","            sns.heatmap(pivot_df, annot=True, fmt='d', cmap='Blues', ax=ax)\n","            ax.set_title(f'Matriz de Confusão\\nFaixa {faixa}')\n","            ax.set_xlabel('Predito')\n","            ax.set_ylabel('Real')\n","\n","        for j in range(num_faixas, len(axes)):\n","            fig.delaxes(axes[j])\n","\n","        plt.suptitle(\"Matriz de Confusão por Faixa\", fontsize=18)\n","        plt.show()\n","\n","    return result\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"kk4keCoEKNDQ","executionInfo":{"status":"ok","timestamp":1763671316008,"user_tz":180,"elapsed":13,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","\n","def plot_all_confusion_matrices_in_grid(df_cm_long, thresholds, title):\n","    \"\"\"\n","    Plota 10 matrizes de confusão em uma única figura em uma grade de 2x5.\n","\n","    Args:\n","        df_cm_long (pd.DataFrame): DataFrame com colunas 'threshold', 'true', 'pred' e 'value_abs'.\n","        thresholds (list or np.array): A lista de thresholds a serem plotados.\n","        title (str): Título principal do gráfico.\n","    \"\"\"\n","    # Cria a figura e a grade de subplots\n","    fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(20, 8))\n","    axes = axes.flatten()  # Acha os eixos para iterar facilmente\n","\n","    # Itera sobre cada threshold e plota uma matriz em um subplot\n","    for idx, t in enumerate(thresholds):\n","        ax = axes[idx]\n","\n","        # Filtra o DataFrame para o threshold atual\n","        df_filtered = df_cm_long[df_cm_long['threshold'] == t]\n","\n","        if df_filtered.empty:\n","            print(f\"Nenhum dado encontrado para o threshold {t}\")\n","            continue\n","\n","        # Transforma para o formato de matriz\n","        cm_matrix = df_filtered.pivot(index='true', columns='pred', values='value_abs')\n","\n","        # Plota o heatmap no subplot atual\n","        sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n","                    xticklabels=['Previsto 0', 'Previsto 1'],\n","                    yticklabels=['Real 0', 'Real 1'], ax=ax)\n","\n","        ax.set_title(f'Threshold: {t:.1f}')\n","        ax.set_xlabel('Classe Prevista')\n","        ax.set_ylabel('Classe Real')\n","\n","    # Configura o título principal e o layout\n","    fig.suptitle(title, fontsize=16)\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ajusta o layout para evitar sobreposição do título\n","    plt.show()"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"opM_Zx5nPgZp","executionInfo":{"status":"ok","timestamp":1763673568771,"user_tz":180,"elapsed":22,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def threshold_experiment_and_classify(\n","    df,\n","    label_cols,\n","    tox_score='toxicity',\n","    do_plots=True\n","):\n","    # Garantir numérico\n","    df[tox_score] = pd.to_numeric(df[tox_score], errors='coerce')\n","\n","    thresholds = np.linspace(0.1, 1.0, 10)\n","\n","    # Listas para as métricas macro (média entre classes)\n","    f1s_macro, precisions_macro, recalls_macro = [], [], []\n","\n","    # Listas para as métricas por classe\n","    f1s_per_class = {'0': [], '1': []}\n","    prec_per_class = {'0': [], '1': []}\n","    rec_per_class = {'0': [], '1': []}\n","\n","    # Matrizes de confusão por threshold (absolutas e normalizadas)\n","    conf_matrices_abs = []\n","    conf_matrices_norm = []\n","\n","    # 1) Label final por maioria entre anotadores\n","    df['label_final'] = df[label_cols].mode(axis=1)[0].astype(int)\n","\n","    # 2) Varre thresholds\n","    for t in thresholds:\n","        df['predicted'] = (df[tox_score] > t).astype(int)\n","\n","        # average=None -> por classe; labels=[0,1] para ordem estável\n","        f1 = f1_score(df['label_final'], df['predicted'], average=None, labels=[0,1], zero_division=0)\n","        pre = precision_score(df['label_final'], df['predicted'], average=None, labels=[0,1], zero_division=0)\n","        rec = recall_score(df['label_final'], df['predicted'], average=None, labels=[0,1], zero_division=0)\n","\n","        # Guarda macro (média simples entre classes)\n","        f1s_macro.append(np.mean(f1))\n","        precisions_macro.append(np.mean(pre))\n","        recalls_macro.append(np.mean(rec))\n","\n","        # Guarda por classe\n","        f1s_per_class['0'].append(float(f1[0]));  f1s_per_class['1'].append(float(f1[1]))\n","        prec_per_class['0'].append(float(pre[0])); prec_per_class['1'].append(float(pre[1]))\n","        rec_per_class['0'].append(float(rec[0]));  rec_per_class['1'].append(float(rec[1]))\n","\n","        # Matrizes de confusão\n","        cm_abs = confusion_matrix(df['label_final'], df['predicted'], labels=[0,1])\n","        cm_norm = confusion_matrix(df['label_final'], df['predicted'], labels=[0,1], normalize='true')\n","        conf_matrices_abs.append(cm_abs)\n","        conf_matrices_norm.append(cm_norm)\n","\n","    # ======= DataFrames requisitados =======\n","    # (1) F1 por classe vs threshold (wide)\n","    df_f1_por_classe = pd.DataFrame({\n","        'threshold': thresholds,\n","        'f1_class_0': f1s_per_class['0'],\n","        'f1_class_1': f1s_per_class['1']\n","    })\n","\n","    # (2) Precision por classe vs threshold (wide)\n","    df_precision_por_classe = pd.DataFrame({\n","        'threshold': thresholds,\n","        'precision_class_0': prec_per_class['0'],\n","        'precision_class_1': prec_per_class['1']\n","    })\n","\n","    # (3) Recall por classe vs threshold (wide)\n","    df_recall_por_classe = pd.DataFrame({\n","        'threshold': thresholds,\n","        'recall_class_0': rec_per_class['0'],\n","        'recall_class_1': rec_per_class['1']\n","    })\n","\n","    # (4) Matrizes de confusão em formato longo\n","    def _cm_list_to_long_df(cm_list, thresholds, value_col):\n","        rows = []\n","        for idx, t in enumerate(thresholds):\n","            cm = cm_list[idx]\n","            for i, true_label in enumerate([0, 1]):\n","                for j, pred_label in enumerate([0, 1]):\n","                    rows.append({\n","                        'threshold': float(t),\n","                        'true': int(true_label),\n","                        'pred': int(pred_label),\n","                        value_col: float(cm[i, j]) if value_col != 'value_abs' else int(cm[i, j])\n","                    })\n","        return pd.DataFrame(rows)\n","\n","    df_cm_abs_long = _cm_list_to_long_df(conf_matrices_abs, thresholds, value_col='value_abs')\n","    df_cm_norm_long = _cm_list_to_long_df(conf_matrices_norm, thresholds, value_col='value_norm')\n","\n","    # (5) Melhor threshold pelo F1 macro\n","    best_index = int(np.argmax(f1s_macro))\n","    best_theta = float(thresholds[best_index])\n","\n","    # (6) Classificação final com melhor threshold\n","    df['toxicity_classification'] = (df[tox_score] > best_theta).astype(int)\n","\n","    # Adicionar a contagem por faixa de toxicidade\n","    bins = np.linspace(0.0, 1.0, 11)\n","    labels = [f'{x:.1f}-{y:.1f}' for x, y in zip(bins[:-1], bins[1:])]\n","    df['toxicity_range'] = pd.cut(df[tox_score], bins=bins, labels=labels, right=False, include_lowest=True)\n","    counts_df = df.groupby(['toxicity_range', 'toxicity_classification']).size().unstack(fill_value=0)\n","    counts_df.columns = [f'predicted_{col}' for col in counts_df.columns]\n","\n","    # (7) Métricas finais\n","    final_precision = precision_score(df['label_final'], df['toxicity_classification'],\n","                                      average=None, labels=[0,1], zero_division=0)\n","    final_recall = recall_score(df['label_final'], df['toxicity_classification'],\n","                                     average=None, labels=[0,1], zero_division=0)\n","    final_f1 = f1_score(df['label_final'], df['toxicity_classification'],\n","                                average=None, labels=[0,1], zero_division=0)\n","    final_accuracy = accuracy_score(df['label_final'], df['toxicity_classification'])\n","\n","    # Suportes por classe\n","    supports = df['label_final'].value_counts().reindex([0,1]).fillna(0).astype(int).to_dict()\n","\n","    # DataFrame com métricas finais por classe\n","    df_final_por_classe = pd.DataFrame([\n","        {\n","            'classe': 0,\n","            'support': int(supports.get(0, 0)),\n","            'precision': float(final_precision[0]),\n","            'recall': float(final_recall[0]),\n","            'f1': float(final_f1[0]),\n","        },\n","        {\n","            'classe': 1,\n","            'support': int(supports.get(1, 0)),\n","            'precision': float(final_precision[1]),\n","            'recall': float(final_recall[1]),\n","            'f1': float(final_f1[1]),\n","        }\n","    ])\n","\n","    metrics = {\n","        'best_threshold': best_theta,\n","        'thresholds': thresholds.tolist(),\n","        'threshold_curves': {\n","            'macro': {\n","                'f1': f1s_macro,\n","                'precision': precisions_macro,\n","                'recall': recalls_macro\n","            },\n","            'per_class': {\n","                '0': {\n","                    'f1': f1s_per_class['0'],\n","                    'precision': prec_per_class['0'],\n","                    'recall': rec_per_class['0']\n","                },\n","                '1': {\n","                    'f1': f1s_per_class['1'],\n","                    'precision': prec_per_class['1'],\n","                    'recall': rec_per_class['1']\n","                }\n","            },\n","            'confusion_matrices': {\n","                'absolute': [cm.tolist() for cm in conf_matrices_abs],\n","                'normalized': [cm.tolist() for cm in conf_matrices_norm]\n","            }\n","        },\n","        'final': {\n","            'accuracy': float(final_accuracy),\n","            'per_class': {\n","                '0': {\n","                    'support': int(supports.get(0, 0)),\n","                    'precision': float(final_precision[0]),\n","                    'recall': float(final_recall[0]),\n","                    'f1': float(final_f1[0]),\n","                },\n","                '1': {\n","                    'support': int(supports.get(1, 0)),\n","                    'precision': float(final_precision[1]),\n","                    'recall': float(final_recall[1]),\n","                    'f1': float(final_f1[1]),\n","                }\n","            }\n","        }\n","    }\n","\n","    # Limpeza da coluna auxiliar\n","    df.drop(columns=['predicted'], errors='ignore', inplace=True)\n","\n","    # Pacote de DataFrames para retornar\n","    dataframes = {\n","        'f1_por_classe_wide': df_f1_por_classe,\n","        'precision_por_classe_wide': df_precision_por_classe,\n","        'recall_por_classe_wide': df_recall_por_classe,\n","        'confusao_abs_long': df_cm_abs_long,\n","        'confusao_norm_long': df_cm_norm_long,\n","        'final_por_classe': df_final_por_classe\n","    }\n","\n","    return df, metrics, dataframes"]},{"cell_type":"markdown","source":["Mostra todas as métricas do detoxify"],"metadata":{"id":"QAJF92FrEVcs"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Re-running threshold_experiment_and_classify to get the metrics object\n","# Parameters are taken from the last detoxify experiment in cell LXGIlffRKNDW\n","df_processed, metrics_detoxify, dfs_detoxify = threshold_experiment_and_classify(\n","    df_anotado.copy(), # Use a copy to avoid modifying the original df_anotado prematurely\n","    label_cols=['toxico1', 'toxico2', 'toxico3'],\n","    tox_score='detoxify_toxicity',\n","    do_plots=False # Set to False to avoid regenerating plots, as the user only asked to display metrics\n",")\n","\n","print(f\"=== MELHOR THRESHOLD (Detoxify): {metrics_detoxify['best_threshold']:.2f} ===\")\n","print(f\"Acurácia Global: {metrics_detoxify['final']['accuracy']:.4f}\")\n","print(\"-\" * 40)\n","\n","print(\"\\n### 1. Tabela Resumo: Métricas Finais por Classe\")\n","print(dfs_detoxify['final_por_classe'].to_string(index=False))\n","print(\"-\" * 40)\n","\n","print(\"\\n### 2. Curvas de Métricas vs Threshold (Macro)\")\n","print(\"F1 Macro:\", [f\"{v:.2f}\" for v in metrics_detoxify['threshold_curves']['macro']['f1']])\n","print(\"Precision Macro:\", [f\"{v:.2f}\" for v in metrics_detoxify['threshold_curves']['macro']['precision']])\n","print(\"Recall Macro:\", [f\"{v:.2f}\" for v in metrics_detoxify['threshold_curves']['macro']['recall']])\n","print(\"-\" * 40)\n","\n","print(\"\\n### 3. Curvas de Métricas vs Threshold (Por Classe - Classe 0)\")\n","print(\"F1 Classe 0:\", [f\"{v:.2f}\" for v in metrics_detoxify['threshold_curves']['per_class']['0']['f1']])\n","print(\"Precision Classe 0:\", [f\"{v:.2f}\" for v in metrics_detoxify['threshold_curves']['per_class']['0']['precision']])\n","print(\"Recall Classe 0:\", [f\"{v:.2f}\" for v in metrics_detoxify['threshold_curves']['per_class']['0']['recall']])\n","print(\"-\" * 40)\n","\n","print(\"\\n### 4. Curvas de Métricas vs Threshold (Por Classe - Classe 1)\")\n","print(\"F1 Classe 1:\", [f\"{v:.2f}\" for v in metrics_detoxify['threshold_curves']['per_class']['1']['f1']])\n","print(\"Precision Classe 1:\", [f\"{v:.2f}\" for v in metrics_detoxify['threshold_curves']['per_class']['1']['precision']])\n","print(\"Recall Classe 1:\", [f\"{v:.2f}\" for v in metrics_detoxify['threshold_curves']['per_class']['1']['recall']])\n","print(\"-\" * 40)\n","\n","print(\"\\n### 5. Matrizes de Confusão Absolutas por Threshold (Lista de Arrays)\")\n","for i, cm in enumerate(metrics_detoxify['threshold_curves']['confusion_matrices']['absolute']):\n","    print(f\"Threshold {metrics_detoxify['thresholds'][i]:.1f}:\\n{np.array(cm)}\")\n","print(\"-\" * 40)\n","\n","print(\"\\n### 6. Matrizes de Confusão Normalizadas por Threshold (Lista de Arrays)\")\n","for i, cm in enumerate(metrics_detoxify['thresholds']):\n","    print(f\"Threshold {metrics_detoxify['thresholds'][i]:.1f}:\\n{np.array(metrics_detoxify['threshold_curves']['confusion_matrices']['normalized'][i])}\")\n","print(\"-\" * 40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kPNWjCcG_RJ","executionInfo":{"status":"ok","timestamp":1763673473361,"user_tz":180,"elapsed":282,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}},"outputId":"2ee1bce9-c474-4886-a833-eccf5f08bcf9"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["=== MELHOR THRESHOLD (Detoxify): 0.30 ===\n","Acurácia Global: 0.7545\n","----------------------------------------\n","\n","### 1. Tabela Resumo: Métricas Finais por Classe\n"," classe  support  precision   recall       f1\n","      0       55   0.507937 0.581818 0.542373\n","      1      165   0.853503 0.812121 0.832298\n","----------------------------------------\n","\n","### 2. Curvas de Métricas vs Threshold (Macro)\n","F1 Macro: ['0.54', '0.67', '0.69', '0.65', '0.62', '0.58', '0.51', '0.43', '0.33', '0.20']\n","Precision Macro: ['0.60', '0.69', '0.68', '0.65', '0.64', '0.64', '0.64', '0.62', '0.64', '0.12']\n","Recall Macro: ['0.55', '0.66', '0.70', '0.69', '0.69', '0.68', '0.65', '0.60', '0.56', '0.50']\n","----------------------------------------\n","\n","### 3. Curvas de Métricas vs Threshold (Por Classe - Classe 0)\n","F1 Classe 0: ['0.24', '0.49', '0.54', '0.53', '0.52', '0.52', '0.49', '0.45', '0.43', '0.40']\n","Precision Classe 0: ['0.43', '0.56', '0.51', '0.44', '0.39', '0.37', '0.33', '0.30', '0.28', '0.25']\n","Recall Classe 0: ['0.16', '0.44', '0.58', '0.67', '0.78', '0.87', '0.93', '0.95', '1.00', '1.00']\n","----------------------------------------\n","\n","### 4. Curvas de Métricas vs Threshold (Por Classe - Classe 1)\n","F1 Classe 1: ['0.84', '0.85', '0.83', '0.78', '0.71', '0.65', '0.54', '0.41', '0.23', '0.00']\n","Precision Classe 1: ['0.77', '0.82', '0.85', '0.87', '0.89', '0.92', '0.94', '0.93', '1.00', '0.00']\n","Recall Classe 1: ['0.93', '0.88', '0.81', '0.71', '0.59', '0.50', '0.38', '0.26', '0.13', '0.00']\n","----------------------------------------\n","\n","### 5. Matrizes de Confusão Absolutas por Threshold (Lista de Arrays)\n","Threshold 0.1:\n","[[  9  46]\n"," [ 12 153]]\n","Threshold 0.2:\n","[[ 24  31]\n"," [ 19 146]]\n","Threshold 0.3:\n","[[ 32  23]\n"," [ 31 134]]\n","Threshold 0.4:\n","[[ 37  18]\n"," [ 48 117]]\n","Threshold 0.5:\n","[[43 12]\n"," [67 98]]\n","Threshold 0.6:\n","[[48  7]\n"," [83 82]]\n","Threshold 0.7:\n","[[ 51   4]\n"," [103  62]]\n","Threshold 0.8:\n","[[ 52   3]\n"," [122  43]]\n","Threshold 0.9:\n","[[ 55   0]\n"," [144  21]]\n","Threshold 1.0:\n","[[ 55   0]\n"," [165   0]]\n","----------------------------------------\n","\n","### 6. Matrizes de Confusão Normalizadas por Threshold (Lista de Arrays)\n","Threshold 0.1:\n","[[0.16363636 0.83636364]\n"," [0.07272727 0.92727273]]\n","Threshold 0.2:\n","[[0.43636364 0.56363636]\n"," [0.11515152 0.88484848]]\n","Threshold 0.3:\n","[[0.58181818 0.41818182]\n"," [0.18787879 0.81212121]]\n","Threshold 0.4:\n","[[0.67272727 0.32727273]\n"," [0.29090909 0.70909091]]\n","Threshold 0.5:\n","[[0.78181818 0.21818182]\n"," [0.40606061 0.59393939]]\n","Threshold 0.6:\n","[[0.87272727 0.12727273]\n"," [0.5030303  0.4969697 ]]\n","Threshold 0.7:\n","[[0.92727273 0.07272727]\n"," [0.62424242 0.37575758]]\n","Threshold 0.8:\n","[[0.94545455 0.05454545]\n"," [0.73939394 0.26060606]]\n","Threshold 0.9:\n","[[1.         0.        ]\n"," [0.87272727 0.12727273]]\n","Threshold 1.0:\n","[[1. 0.]\n"," [1. 0.]]\n","----------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3827924404.py:109: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  counts_df = df.groupby(['toxicity_range', 'toxicity_classification']).size().unstack(fill_value=0)\n"]}]},{"cell_type":"markdown","source":["Organiza as métricas em um dataframe (visualmente mais organizado)"],"metadata":{"id":"XLu0IUrJI1TF"}},{"cell_type":"code","source":["# --- 1. Execução do Experimento ---\n","df_processado, metricas_dict, dfs_extras = threshold_experiment_and_classify(\n","    df_anotado.copy(),\n","    label_cols=['toxico1', 'toxico2', 'toxico3'],\n","    tox_score='detoxify_toxicity',\n","    do_plots=False\n",")\n","\n","# --- 2. Extração de Métricas ---\n","c0 = metricas_dict['final']['per_class']['0']\n","c1 = metricas_dict['final']['per_class']['1']\n","\n","# --- 3. Cálculo de Macros ---\n","macro_prec = (c0['precision'] + c1['precision']) / 2\n","macro_rec  = (c0['recall']    + c1['recall'])    / 2\n","macro_f1_val = (c0['f1']      + c1['f1'])        / 2\n","\n","# --- 4. Criação do DataFrame (Nomes Exatos) ---\n","df_tabela_metricas = pd.DataFrame([{\n","    'model/test':      'Detoxify',\n","    'macro_precision': macro_prec,\n","    'macro_recall':    macro_rec,\n","    'macro_f1':        macro_f1_val,\n","    'class0precision': c0['precision'],\n","    'class0recall':    c0['recall'],\n","    'class0f1':        c0['f1'],\n","    'class1precision': c1['precision'],\n","    'class1recall':    c1['recall'],\n","    'class1f1':        c1['f1']\n","}])\n","\n","# --- 5. Exibição ---\n","print(f\"=== Threshold: {metricas_dict['best_threshold']} | Acurácia: {metricas_dict['final']['accuracy']:.4f} ===\")\n","display(df_tabela_metricas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"ko6kcjuuI6Aq","executionInfo":{"status":"ok","timestamp":1763673841408,"user_tz":180,"elapsed":163,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}},"outputId":"0beb43b0-2529-4f91-d5b4-bb2c587372c4"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Threshold: 0.30000000000000004 | Acurácia: 0.7545 ===\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3827924404.py:109: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  counts_df = df.groupby(['toxicity_range', 'toxicity_classification']).size().unstack(fill_value=0)\n"]},{"output_type":"display_data","data":{"text/plain":["  model/test  macro_precision  macro_recall  macro_f1  class0precision  \\\n","0   Detoxify          0.68072       0.69697  0.687336         0.507937   \n","\n","   class0recall  class0f1  class1precision  class1recall  class1f1  \n","0      0.581818  0.542373         0.853503      0.812121  0.832298  "],"text/html":["\n","  <div id=\"df-fbc9303d-8693-408b-bdf3-6d450f153df6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model/test</th>\n","      <th>macro_precision</th>\n","      <th>macro_recall</th>\n","      <th>macro_f1</th>\n","      <th>class0precision</th>\n","      <th>class0recall</th>\n","      <th>class0f1</th>\n","      <th>class1precision</th>\n","      <th>class1recall</th>\n","      <th>class1f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Detoxify</td>\n","      <td>0.68072</td>\n","      <td>0.69697</td>\n","      <td>0.687336</td>\n","      <td>0.507937</td>\n","      <td>0.581818</td>\n","      <td>0.542373</td>\n","      <td>0.853503</td>\n","      <td>0.812121</td>\n","      <td>0.832298</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbc9303d-8693-408b-bdf3-6d450f153df6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fbc9303d-8693-408b-bdf3-6d450f153df6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fbc9303d-8693-408b-bdf3-6d450f153df6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_f7d6f23f-8e39-428f-86c2-5347d983ed3c\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_tabela_metricas')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f7d6f23f-8e39-428f-86c2-5347d983ed3c button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_tabela_metricas');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_tabela_metricas","summary":"{\n  \"name\": \"df_tabela_metricas\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"model/test\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Detoxify\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6807198463249419,\n        \"max\": 0.6807198463249419,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6807198463249419\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.696969696969697,\n        \"max\": 0.696969696969697,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.696969696969697\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6873355090009474,\n        \"max\": 0.6873355090009474,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6873355090009474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class0precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5079365079365079,\n        \"max\": 0.5079365079365079,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5079365079365079\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class0recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5818181818181818,\n        \"max\": 0.5818181818181818,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5818181818181818\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class0f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5423728813559322,\n        \"max\": 0.5423728813559322,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5423728813559322\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class1precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8535031847133758,\n        \"max\": 0.8535031847133758,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8535031847133758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class1recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8121212121212121,\n        \"max\": 0.8121212121212121,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8121212121212121\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class1f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8322981366459627,\n        \"max\": 0.8322981366459627,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8322981366459627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"markdown","source":["Gera a Matriz de Confusão"],"metadata":{"id":"M-LT0834Jjl2"}},{"cell_type":"code","source":[],"metadata":{"id":"nf6XZ5M-Jl6O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RHt71VGS0-os"},"source":["# Detoxify"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"ifQ8ACHYU3zx","executionInfo":{"status":"ok","timestamp":1763671316073,"user_tz":180,"elapsed":14,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def plot_toxicity_cdf(df, column):\n","    # 1. Pega a coluna de toxicidade de todos os vídeos\n","    toxicity_scores = df[column].dropna().values\n","\n","    # 2. Ordena os valores em ordem crescente (essencial para CDF)\n","    sorted_scores = np.sort(toxicity_scores)\n","\n","    # 3. Cria os valores acumulados (proporção)\n","    cdf = np.arange(1, len(sorted_scores) + 1) / len(sorted_scores)\n","\n","    # 4. Cria o gráfico\n","    plt.figure(figsize=(6, 3))\n","    plt.plot(sorted_scores, cdf, color='darkred', lw=2, label='CDF')\n","\n","    # 5. Adiciona linha vertical no ponto 0.7\n","    plt.axvline(x=0.7, color='gray', linestyle='--', lw=1)\n","    plt.text(0.7, 0.05, '0.7', ha='center', fontsize=8)\n","\n","    # 6. Calcula e mostra % de vídeos com toxicidade > 0.7\n","    perc_above = np.sum(toxicity_scores > 0.7) / len(toxicity_scores) * 100\n","    plt.text(0.72, 0.6, f'{perc_above:.1f}% > 0.7', color='black', fontsize=9)\n","\n","    # 7. Formatações finais\n","    plt.xlabel(column)\n","    plt.ylabel(\"Proporção Acumulada (CDF)\")\n","    plt.grid(False)\n","    plt.ylim(0, 1.01)\n","    plt.xlim(0, 1)\n","    plt.tight_layout()\n","    plt.show()\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Z8bEQ8GyuETb","executionInfo":{"status":"ok","timestamp":1763671316087,"user_tz":180,"elapsed":12,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["import pandas as pd\n","# from google.colab import drive\n","\n","# drive.mount('/content/drive')\n","folder_path = ''\n","\n","def experimento(df_merged, algoritmo, tox_cols, tox_score, min_val, max_val, n_bins, label1, label2, label3):\n","  print(\"Ground truth por classe -----------------------------------------\")\n","  df_merged = plot_ground_truth_por_classe(df_merged, tox_score, label_cols=[label1, label2, label3])\n","  print(\"Anotações por classe por faixa -----------------------------------------\")\n","  result = tabela_anotacao_por_faixa(df_merged, tox_score, min_val, max_val, n_bins)\n","  df_final, metrics, dfs = threshold_experiment_and_classify(\n","      df_merged,\n","      label_cols=[label1, label2, label3],\n","      tox_score=tox_score,\n","      do_plots=False\n","  )\n","\n","  # Métricas finais por classe\n","  final_cls0 = metrics['final']['per_class']['0']\n","  final_cls1 = metrics['final']['per_class']['1']\n","\n","  print(\"Melhor theta:\", metrics['best_threshold'])\n","\n","  print(\"\\n=== F1 por classe (wide) ===\")\n","  print(dfs['f1_por_classe_wide'].to_string(index=False))\n","\n","  print(\"\\n=== Precision por classe (wide) ===\")\n","  print(dfs['precision_por_classe_wide'].to_string(index=False))\n","\n","  print(\"\\n=== Recall por classe (wide) ===\")\n","  print(dfs['recall_por_classe_wide'].to_string(index=False))\n","\n","  print(\"\\n=== Matriz de confusão (absoluta) ===\")\n","  df_cm_abs_long = dfs['confusao_abs_long']\n","\n","  # Chamar a função de plotagem\n","  thresholds_list = np.linspace(0.1, 1.0, 10)\n","  plot_all_confusion_matrices_in_grid(\n","    df_cm_long=df_cm_abs_long,\n","    thresholds=thresholds_list,\n","    title='Matrizes de Confusão Absoluta por Threshold'\n","  )\n","\n","  print(\"\\n=== Métricas finais por classe ===\")\n","  print(dfs['final_por_classe'].to_string(index=False))\n","\n","  df_merged.to_csv(folder_path + f'classificados_{algoritmo}_apos_tunning.csv')"]},{"cell_type":"markdown","metadata":{"id":"nyDsB1En1Bfr"},"source":["## Detoxify Misoginia"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"YLo-9UMp0MEf","colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["4cdbbe5a2310468892f7e234e55a30af","668f6956ca0340cc9f12ff8803a4f21b","e19f936d353a4c52aa0ec7594f362853","33ec3de1df8548d9b6ed01194a119385","b8e204342f774f90b3df21dd3bcfe8da","58d2560ec2d7413c8afb5c2ad7f4a1d9","437f131a684f4c5dbd24c479b3e8ecc8","162393fcd43d4a88b19c0359eef46f2f","470f5f213c604d9f83ba273e8411a4ee","5ec95682eb5e4835bf91a93db198e822","2b1b581391804ad49e99f63fc491805d","c94f1927f5414d6db6d652cd24cd8487","c88f86a013684500a6085b9576666b2d","c39ea4df8c5147249c9e685ab5d72329","8e9647797f974e90ace4785f778a893f","8de3545406064d05aa2e7f4c2eae7b24","8874c2912e2b456ba28554b2fdc5d81b","66f426ebc3c84278a857060d2af65c61","3b66e73a36de46cea9696a2d6038b15e","d0c21ac39e9543a2beaae11edd066df2","2d956c3c53764a4299c6f65c857bf596","d2b26ebcd3fd46e58e6c7790a475ae06","e12042a7093b4d5eb6835c9ec2280e6d","9465ffbb617c4e6081d21315e9c94670","66ff3f78bcda463e9b439bdf7548226f","ae26a033e07643d6b6cfb87ebd59349e","4948e011443f4d2aa8e6a33a50f46231","47e6dc9a570b47fd8578bf8e44bdfb4b","1f98ebbdbc3b4b66b27aea94cae6a4a5","e18a973e097443c69726c5c832f39d9f","947e3eab2303426ca0ff8d851618ba47","858aedcf490e47d7a06b25bc7c3ad67c","f79cf810b5804e90a436beae2c8649d7","24ae152ec0cc4b74b2eda3ff9124f13c","01fd22d60abd4d12ba08c4e7a0539ea9","7afcbcce496d47aa9fbd7f917ffcf5f5","d6d83997d77e4983a4bbbb29fd82fd0c","887a6b76695b4ac7a5fe554c52f3c433","43e55e132512423b8edeb7422bc0cd51","fa074255b8fc4b52a07113d969cb2128","700654ea81dd418683b4f6b627305ba7","5faae99a9d5a45eab2f7e92ed6fb3a51","13ee8cd2d466466a8bbf4e7aceb6ca8b","f5e7de55e4874021963d619cd72455bf"]},"executionInfo":{"status":"ok","timestamp":1763671372020,"user_tz":180,"elapsed":55879,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}},"outputId":"2440a4ee-a7fa-45d2-ad2c-b6be035abe09"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/unitaryai/detoxify/releases/download/v0.4-alpha/multilingual_debiased-0b549669.ckpt\" to /root/.cache/torch/hub/checkpoints/multilingual_debiased-0b549669.ckpt\n","100%|██████████| 1.04G/1.04G [00:20<00:00, 54.8MB/s]\n","/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cdbbe5a2310468892f7e234e55a30af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c94f1927f5414d6db6d652cd24cd8487"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e12042a7093b4d5eb6835c9ec2280e6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24ae152ec0cc4b74b2eda3ff9124f13c"}},"metadata":{}}],"source":["import pandas as pd\n","from detoxify import Detoxify\n","from tqdm import tqdm\n","\n","# Certifique-se de que seu DataFrame possui a coluna 'text'\n","# Exemplo: df_videos = pd.DataFrame({'text': [\"Você é incrível\", \"Seu idiota nojento!\"]})\n","\n","# Carrega o modelo adequado para múltiplos idiomas\n","model = Detoxify('multilingual')\n","\n","# Função para aplicar a análise linha a linha\n","def analyze_toxicity_detoxify(texts):\n","    results = []\n","    for text in tqdm(texts, desc=\"Analisando toxicidade\"):\n","        try:\n","            scores = model.predict(text)\n","        except Exception:\n","            # Se ocorrer erro, retorna pontuações nulas\n","            scores = {k: None for k in model.predict(\"teste\").keys()}\n","        results.append(scores)\n","    return results"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"kFZuPirC0R3S","executionInfo":{"status":"ok","timestamp":1763671372032,"user_tz":180,"elapsed":10,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["from detoxify import Detoxify\n","import pandas as pd\n","\n","def classificar_com_detoxify(df_para_classificar: pd.DataFrame, df_scores_detoxify: pd.DataFrame) -> pd.DataFrame:\n","    RESP_COL = \"text\"\n","    DETOX_PREFIX = \"detoxify_\"\n","\n","    # ===== Selecionar colunas de interesse nos scores salvos =====\n","    detox_cols = [col for col in df_scores_detoxify.columns if col.startswith(DETOX_PREFIX)]\n","    cols_para_merge = [RESP_COL] + detox_cols\n","\n","    # ===== Remover duplicatas nos textos de scores salvos =====\n","    df_scores_unicos = df_scores_detoxify[cols_para_merge].drop_duplicates(subset=[RESP_COL])\n","\n","    # ===== Fazer merge para adicionar os scores existentes =====\n","    df_classificado = df_para_classificar.merge(\n","        df_scores_unicos,\n","        on=RESP_COL,\n","        how='left'\n","    )\n","\n","    # ===== Identificar textos ainda não classificados =====\n","    df_nao_classificados = df_classificado[\n","        df_classificado[f\"{DETOX_PREFIX}toxicity\"].isnull() & df_classificado[RESP_COL].notnull()\n","    ]\n","\n","    print(f\"Textos novos para classificar: {len(df_nao_classificados)}\")\n","\n","    # ===== Classificar os textos restantes =====\n","    if not df_nao_classificados.empty:\n","        model = Detoxify('multilingual')\n","        textos_novos = df_nao_classificados[RESP_COL].tolist()\n","        resultados = model.predict(textos_novos)\n","\n","        # ===== Atribuir os resultados aos índices corretos =====\n","        idxs_para_preencher = df_classificado[\n","            df_classificado[f\"{DETOX_PREFIX}toxicity\"].isnull()\n","        ].index\n","\n","        for key in resultados:\n","            col_name = f\"{DETOX_PREFIX}{key}\"\n","            df_classificado.loc[idxs_para_preencher, col_name] = resultados[key]\n","\n","    return df_classificado\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xBWi5TEu0S-0","outputId":"f004035e-cadf-476e-9ea3-78903c3d9c44","executionInfo":{"status":"ok","timestamp":1763672283253,"user_tz":180,"elapsed":251118,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Lendo anotações -----------------------------------------\n","Mounted at /content/drive\n","Lendo scores previamente calculados ----------------------\n","Index(['text', 'misoginia1', 'misoginia2', 'misoginia3', 'toxico1', 'toxico2',\n","       'toxico3', 'categoria1', 'categoria2', 'categoria3'],\n","      dtype='object') Index(['Unnamed: 0', 'published_at', 'category_id', 'tags', 'view_count',\n","       'like_count', 'comment_count', 'duration', 'definition', 'caption',\n","       'licensed_content', 'privacy_status', 'license', 'embeddable',\n","       'public_stats_viewable', 'is_made_for_kids', 'thumbnail_url',\n","       'default_audio_language', 'default_language', 'actual_start_time',\n","       'scheduled_start_time', 'actual_end_time', 'scheduled_end_time',\n","       'concurrent_viewers', 'active_live_chat_id', 'recording_date',\n","       'topicCategories', 'processing_status', 'parts_total',\n","       'parts_processed', 'time_left_ms', 'processing_failure_reason',\n","       'transcription', 'id_canal_anonimizado', 'id_video_anonimizado', 'text',\n","       'emojis', 'hashtags', 'detoxify_toxicity', 'detoxify_severe_toxicity',\n","       'detoxify_obscene', 'detoxify_identity_attack', 'detoxify_insult',\n","       'detoxify_threat', 'detoxify_sexual_explicit', 'guardrail_score',\n","       'doug_health_score', 'doug_ideology_score', 'doug_insult_score',\n","       'doug_lgbtqphobia_score', 'doug_other_lifestyle_score',\n","       'doug_physical_aspects_score', 'doug_profanity_obscene_score',\n","       'doug_racism_score', 'doug_sexism_score', 'doug_xenophobia_score'],\n","      dtype='object')\n","Classsificando textos -------------------------------------\n","Textos novos para classificar: 205\n"]}],"source":["import pandas as pd\n","\n","tox_score = 'toxicity'\n","\n","print(\"Lendo anotações -----------------------------------------\")\n","\n","import pandas as pd\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","folder_path = '/content/drive/MyDrive/red_pill_analises/data_base/dados_anotados/'\n","\n","df_ground_truth = pd.read_csv(folder_path + 'anotacoes_completas.csv', encoding='utf-8')\n","df_ground_truth.rename(columns={'texto_original': 'text'}, inplace=True)\n","\n","print(\"Lendo scores previamente calculados ----------------------\")\n","df_scores_detoxify = pd.read_csv('/content/drive/MyDrive/red_pill_analises/data_base/resultados/' + 'videos_com_scores_de_toxicidade.csv')\n","\n","tox_cols = ['toxicity', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']\n","algoritmo = 'videos_com_detoxify'\n","\n","print(df_ground_truth.columns, df_scores_detoxify.columns)\n","\n","print(\"Classsificando textos -------------------------------------\")\n","df_anotado = classificar_com_detoxify(df_ground_truth, df_scores_detoxify)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Qn67Y7AKNDV","executionInfo":{"status":"aborted","timestamp":1763671493559,"user_tz":180,"elapsed":471027,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["df_anotado.to_csv('scores_detoxify_atualizado.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6B5KeN4oKNDW","executionInfo":{"status":"aborted","timestamp":1763671493562,"user_tz":180,"elapsed":471027,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["df_anotado = pd.read_csv('scores_detoxify_atualizado.csv')\n","\n","tox_cols = ['detoxify_toxicity']\n","\n","df_anotado['is_offensive'] = (df_anotado['detoxify_toxicity'] > 0.7).astype(int)\n","df_anotado.head()\n","\n","print(df_anotado.columns)\n","\n","experimento(df_anotado, algoritmo, tox_cols, 'detoxify_toxicity', min_val=0, max_val=1, n_bins=10, label1='misoginia1', label2='misoginia2', label3='misoginia3')\n","\n","df_anotado.to_csv('anotado_detoxify_misoginia.csv')"]},{"cell_type":"markdown","metadata":{"id":"KM_iqMNTKNDW"},"source":["## Detoxify para Toxicidade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LXGIlffRKNDW","executionInfo":{"status":"aborted","timestamp":1763671493564,"user_tz":180,"elapsed":471025,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["tox_cols = ['detoxify_toxicity', 'detoxify_severe_toxicity', 'detoxify_obscene', 'detoxify_identity_attack', 'detoxify_insult', 'detoxify_threat']\n","\n","df_anotado['is_offensive'] = (df_anotado[tox_cols] >= 0.7).any(axis=1).astype(int)\n","df_anotado.head()\n","\n","print(df_anotado.columns)\n","\n","experimento(df_anotado, algoritmo, tox_cols, 'detoxify_toxicity', min_val=0, max_val=1, n_bins=10, label1='toxico1', label2='toxico2', label3='toxico3')\n","\n","df_anotado.to_csv('anotado_detoxify_misoginia.csv')"]},{"cell_type":"markdown","metadata":{"id":"YAnwcXqsuDyi"},"source":["# GuardRail"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ckRVj-x2NOD","executionInfo":{"status":"aborted","timestamp":1763671493566,"user_tz":180,"elapsed":471026,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["import pandas as pd\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","def score_toxiguardrail_prompt_fixo(\n","    tokenizer,\n","    device,\n","    toxiGuardrail,\n","    df: pd.DataFrame,\n","    response_col: str,\n","    prompt: str,\n","    batch_size: int = 32,\n","    max_length: int = 512,\n",") -> pd.Series:\n","    responses = df[response_col].fillna(\"\").astype(str).tolist()\n","    prompts = [prompt] * len(responses)\n","\n","    scores = []\n","    for i in range(0, len(responses), batch_size):\n","        p_batch = prompts[i:i+batch_size]\n","        r_batch = responses[i:i+batch_size]\n","\n","        tokens = tokenizer(\n","            p_batch,\n","            r_batch,\n","            truncation=True,\n","            max_length=max_length,\n","            padding=True,\n","            return_token_type_ids=False,\n","            return_attention_mask=True,\n","            return_tensors=\"pt\",\n","        )\n","        tokens = {k: v.to(device) for k, v in tokens.items()}\n","\n","        with torch.no_grad():\n","            out = toxiGuardrail(**tokens)\n","            logits = out.logits\n","\n","        if logits.ndim == 2 and logits.shape[1] == 1:\n","            batch_scores = logits.squeeze(-1).detach().cpu().tolist()\n","        else:\n","            probs = torch.softmax(logits, dim=-1).detach().cpu()\n","            id2label = toxiGuardrail.config.id2label\n","            toxic_idx = None\n","            for k, v in id2label.items():\n","                name = str(v).lower()\n","                if any(x in name for x in [\"toxic\", \"unsafe\", \"harm\", \"tóxic\", \"viol\", \"negat\"]):\n","                    toxic_idx = int(k)\n","                    break\n","            if toxic_idx is None:\n","                toxic_idx = 1 if probs.shape[1] > 1 else 0\n","            batch_scores = probs[:, toxic_idx].tolist()\n","\n","        scores.extend(batch_scores)\n","\n","    return pd.Series(scores, index=df.index, name=\"guardrail_score\")\n","\n","def classificar_com_guardrail(df_para_classificar: pd.DataFrame, df_scores_guardrail: pd.DataFrame) -> pd.DataFrame:\n","    RESP_COL = \"text\"\n","    SCORE_COL = \"guardrail_score\"\n","\n","    # ===== Selecionar colunas de interesse =====\n","    cols_para_merge = [RESP_COL, SCORE_COL]\n","\n","    # ===== Remover duplicatas dos scores =====\n","    df_scores_unicos = df_scores_guardrail[cols_para_merge].drop_duplicates(subset=[RESP_COL])\n","\n","    # ===== Fazer merge para adicionar os scores existentes =====\n","    df_classificado = df_para_classificar.merge(\n","        df_scores_unicos,\n","        on=RESP_COL,\n","        how='left'\n","    )\n","\n","    # ===== Identificar textos ainda não classificados =====\n","    df_nao_classificados = df_classificado[\n","        df_classificado[SCORE_COL].isnull() & df_classificado[RESP_COL].notnull()\n","    ]\n","\n","    print(f\"Textos novos para classificar com Guardrail: {len(df_nao_classificados)}\")\n","\n","    # ===== Classificar os textos restantes =====\n","    if not df_nao_classificados.empty:\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        CKPT = \"nicholasKluge/ToxiGuardrailPT\"\n","        tokenizer = AutoTokenizer.from_pretrained(CKPT)\n","        toxiGuardrail = AutoModelForSequenceClassification.from_pretrained(CKPT)\n","        toxiGuardrail.eval().to(device)\n","\n","        prompt = \"Classifique textos que são misóginos ou não\"\n","\n","        novos_scores = score_toxiguardrail_prompt_fixo(\n","            tokenizer,\n","            device,\n","            toxiGuardrail,\n","            df_nao_classificados,\n","            response_col=RESP_COL,\n","            prompt=prompt,\n","            batch_size=32,\n","            max_length=512\n","        )\n","\n","        # ===== Atribuir os resultados aos índices corretos =====\n","        idxs_para_preencher = df_classificado[\n","            df_classificado[SCORE_COL].isnull()\n","        ].index\n","\n","        df_classificado.loc[idxs_para_preencher, SCORE_COL] = novos_scores\n","\n","    return df_classificado\n"]},{"cell_type":"markdown","metadata":{"id":"gWrxgYeVxyAH"},"source":["## ToxiGuard para Misoginia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TIQ2FlBrKNDY","executionInfo":{"status":"aborted","timestamp":1763671493567,"user_tz":180,"elapsed":471023,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["df_anotado = classificar_com_guardrail(df_ground_truth, df_scores_detoxify)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAx8Ka7dTFJm","executionInfo":{"status":"aborted","timestamp":1763671493571,"user_tz":180,"elapsed":471027,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["df_anotado1 = df_anotado\n","experimento(df_anotado1, algoritmo, tox_cols, 'guardrail_score', min_val=-6, max_val=6, n_bins=10, label1='misoginia1', label2='misoginia2', label3='misoginia3')"]},{"cell_type":"markdown","metadata":{"id":"pwJXd_oex6Ov"},"source":["## ToxiGuard para Toxicidade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YaIpFSyVuPKe","executionInfo":{"status":"aborted","timestamp":1763671493573,"user_tz":180,"elapsed":471028,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["tox_score = 'guardrail_score'\n","tox_cols = ['guardrail_score']\n","\n","df_anotado['is_offensive'] = (df_anotado['guardrail_score'] <= -0.5).astype(int)\n","df_anotado.head()\n","\n","experimento(df_anotado, algoritmo, tox_cols, 'guardrail_score', min_val=-6, max_val=6, n_bins=10, label1='toxico1', label2='toxico2', label3='toxico3')\n","\n","df_anotado.to_csv('anotado_toxiguard_toxicidade.csv')"]},{"cell_type":"markdown","metadata":{"id":"8pXrQy9KEU3L"},"source":["# Doug Trajano"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxOZf67RF338","executionInfo":{"status":"aborted","timestamp":1763671493574,"user_tz":180,"elapsed":471029,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["import pandas as pd\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","def classificar_com_dougtrajano(df_para_classificar: pd.DataFrame, df_scores_doug: pd.DataFrame) -> pd.DataFrame:\n","    RESP_COL = \"text\"  # coluna com os textos\n","    PREFIX = \"doug_tox_\"\n","\n","    # ===== Selecionar colunas de interesse nos scores salvos =====\n","    cols_para_merge = [col for col in df_scores_doug.columns if col.startswith(PREFIX)]\n","    cols_para_merge = [RESP_COL] + cols_para_merge\n","\n","    # ===== Remover duplicatas nos textos de scores salvos =====\n","    df_scores_unicos = df_scores_doug[cols_para_merge].drop_duplicates(subset=[RESP_COL])\n","\n","    # ===== Fazer merge para adicionar os scores existentes =====\n","    df_classificado = df_para_classificar.merge(\n","        df_scores_unicos,\n","        on=RESP_COL,\n","        how=\"left\"\n","    )\n","\n","    # ===== Identificar textos ainda não classificados =====\n","    alguma_col_score = [col for col in df_classificado.columns if col.startswith(f\"{PREFIX}\") and col.endswith(\"_score\")]\n","    if alguma_col_score:\n","        df_nao_classificados = df_classificado[df_classificado[alguma_col_score[0]].isnull() & df_classificado[RESP_COL].notnull()]\n","    else:\n","        df_nao_classificados = df_classificado[df_classificado[RESP_COL].notnull()]\n","\n","    print(f\"Textos novos para classificar: {len(df_nao_classificados)}\")\n","\n","    # ===== Classificar os textos restantes =====\n","    if not df_nao_classificados.empty:\n","        CKPT = \"dougtrajano/toxicity-type-detection\"\n","        tokenizer = AutoTokenizer.from_pretrained(CKPT)\n","        model = AutoModelForSequenceClassification.from_pretrained(CKPT)\n","        model.eval()\n","\n","        # Detectar tipo de problema automaticamente (ou force se necessário)\n","        # model.config.problem_type = \"multi_label_classification\"\n","\n","        def analyze_toxicity(texts: pd.Series, model, tokenizer):\n","            from torch.nn.functional import sigmoid, softmax\n","\n","            max_pos = getattr(model.config, \"max_position_embeddings\", 512)\n","            window = max_pos - 2  # para CLS e SEP\n","            stride = 64\n","            microbatch_size = 16\n","            problem_type = getattr(model.config, \"problem_type\", None)\n","\n","            id2label = model.config.id2label\n","            num_labels = model.config.num_labels\n","            labels = [id2label[i] for i in range(num_labels)]\n","\n","            PAD_ID = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0\n","\n","            def _chunks_by_tokens(text: str):\n","                enc_full = tokenizer(text, add_special_tokens=False, return_attention_mask=False)\n","                ids = enc_full[\"input_ids\"]\n","                if len(ids) <= window:\n","                    return [tokenizer.build_inputs_with_special_tokens(ids)]\n","                chunks = []\n","                start = 0\n","                while start < len(ids):\n","                    end = min(start + window, len(ids))\n","                    chunk_ids = tokenizer.build_inputs_with_special_tokens(ids[start:end])\n","                    chunks.append(chunk_ids)\n","                    if end == len(ids):\n","                        break\n","                    start = max(0, end - stride)\n","                return chunks\n","\n","            def _pad_batch(batch):\n","                max_len_batch = max(len(ids) for ids in batch)\n","                input_ids = []\n","                attn_masks = []\n","                for ids in batch:\n","                    pad_len = max_len_batch - len(ids)\n","                    input_ids.append(ids + [PAD_ID] * pad_len)\n","                    attn_masks.append([1] * len(ids) + [0] * pad_len)\n","                input_ids = torch.tensor(input_ids, dtype=torch.long, device=device)\n","                attn_masks = torch.tensor(attn_masks, dtype=torch.long, device=device)\n","                return input_ids, attn_masks\n","\n","            def _forward_on_chunks(chunks):\n","                logits_list = []\n","                for i in range(0, len(chunks), microbatch_size):\n","                    batch = chunks[i:i + microbatch_size]\n","                    input_ids, attention_mask = _pad_batch(batch)\n","                    with torch.no_grad():\n","                        out = model(input_ids=input_ids, attention_mask=attention_mask)\n","                    logits_list.append(out.logits.detach().cpu())\n","                return torch.cat(logits_list, dim=0)\n","\n","            rows = []\n","            for text in texts.fillna(\"\").astype(str):\n","                chunks = _chunks_by_tokens(text)\n","                if not chunks:\n","                    score_vec = [0.0] * num_labels\n","                    bin_vec = [0] * num_labels\n","                else:\n","                    logits = _forward_on_chunks(chunks)\n","                    if problem_type == \"multi_label_classification\":\n","                        probs = sigmoid(logits)\n","                        agg = probs.max(dim=0).values\n","                        score_vec = agg.tolist()\n","                        bin_vec = [int(s >= 0.5) for s in score_vec]\n","                    else:\n","                        probs = softmax(logits, dim=-1)\n","                        agg = probs.mean(dim=0)\n","                        score_vec = agg.tolist()\n","                        top1 = int(torch.argmax(agg).item())\n","                        bin_vec = [1 if i == top1 else 0 for i in range(num_labels)]\n","\n","                row = {}\n","                for i, label in enumerate(labels):\n","                    row[f\"{PREFIX}{label}_score\"] = float(score_vec[i])\n","                    row[f\"{PREFIX}{label}_pred\"] = int(bin_vec[i])\n","                rows.append(row)\n","\n","            return pd.DataFrame(rows)\n","\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        model.to(device)\n","\n","        novos_scores = analyze_toxicity(df_nao_classificados[RESP_COL], model, tokenizer)\n","        novos_scores[RESP_COL] = df_nao_classificados[RESP_COL].values\n","\n","        # ===== Recombinar os resultados =====\n","        df_classificado = df_classificado.drop(columns=[col for col in df_classificado.columns if col.startswith(PREFIX)], errors=\"ignore\")\n","        df_classificado = df_classificado.merge(novos_scores, on=RESP_COL, how=\"left\")\n","\n","    return df_classificado\n"]},{"cell_type":"markdown","metadata":{"id":"OaP-nE3ixjzq"},"source":["## OLID BR Misoginia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LzQaprpEXP1","executionInfo":{"status":"aborted","timestamp":1763671493575,"user_tz":180,"elapsed":471029,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["tox_score = 'tox_sexism_score'\n","\n","print(\"Classificando sampled_df ---------------\")\n","algoritmo = 'videos_com_dougtrajano'\n","df_anotado = classificar_com_dougtrajano(df_ground_truth, df_scores_detoxify)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRL2J2bWKNDb","executionInfo":{"status":"aborted","timestamp":1763671493578,"user_tz":180,"elapsed":471032,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["print(\"Identificando ofensivos ---------------\")\n","print(len(df_anotado))\n","print(df_anotado.columns)\n","df_anotado['is_offensive'] = df_anotado['doug_tox_sexism_pred']\n","\n","print(\"Identificou os textos ofensivos\")\n","print(df_anotado.head())\n","\n","#tox_cols = ['toxicity', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']\n","tox_cols = ['doug_tox_insult_score', 'doug_tox_lgbtqphobia_score',\n","       'doug_tox_other_lifestyle_score', 'doug_tox_physical_aspects_score',\n","       'doug_tox_profanity_obscene_score', 'doug_tox_racism_score', 'doug_tox_sexism_score',\n","       'doug_tox_xenophobia_score']\n","algoritmo = 'videos_com_dougtrajano'\n","\n","df_olid = df_anotado\n","print(df_anotado.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0osug7YAbCA3","executionInfo":{"status":"aborted","timestamp":1763671493579,"user_tz":180,"elapsed":471032,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["print(df_anotado.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCYph4GdaCJ-","executionInfo":{"status":"aborted","timestamp":1763671493580,"user_tz":180,"elapsed":471033,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["from collections import defaultdict\n","\n","# 1. Renomeia colunas duplicadas com sufixo _dupX para que fiquem únicas temporariamente\n","def rename_duplicate_columns(df):\n","    seen = defaultdict(int)\n","    new_cols = []\n","    for col in df.columns:\n","        count = seen[col]\n","        if count:\n","            new_cols.append(f\"{col}_dup{count}\")\n","        else:\n","            new_cols.append(col)\n","        seen[col] += 1\n","    df.columns = new_cols\n","    return df\n","\n","df_anotado = rename_duplicate_columns(df_anotado)\n","\n","# 2. Encontra todas as colunas que eram 'tox_sexism_score'\n","sexism_cols = [col for col in df_anotado.columns if col.startswith('tox_sexism_score')]\n","\n","if len(sexism_cols) > 1:\n","    # 3. Calcula número de NaN para cada uma\n","    null_counts = [df_anotado[col].isnull().sum() for col in sexism_cols]\n","\n","    # 4. Identifica a que tem mais NaN e remove\n","    col_to_drop = sexism_cols[null_counts.index(max(null_counts))]\n","    df_anotado.drop(columns=col_to_drop, inplace=True)\n","\n","    # 5. Renomeia a que sobrou (a boa) para 'tox_sexism_score'\n","    for col in sexism_cols:\n","        if col != col_to_drop:\n","            df_anotado.rename(columns={col: 'tox_sexism_score'}, inplace=True)\n","            break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZunnaFOaw3i","executionInfo":{"status":"aborted","timestamp":1763671493581,"user_tz":180,"elapsed":471034,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["df_anotado['doug_tox_sexism_score']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PuEnXJlFZZE3","executionInfo":{"status":"aborted","timestamp":1763671493582,"user_tz":180,"elapsed":471034,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["print(\"Iniciando experimento -------------------\")\n","experimento(df_anotado, algoritmo=algoritmo, tox_cols=tox_cols, tox_score='doug_tox_sexism_score', min_val=0, max_val=1, n_bins=10, label1=\"misoginia1\", label2=\"misoginia2\", label3=\"misoginia3\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leu8Qr8UZJSH","executionInfo":{"status":"aborted","timestamp":1763671493584,"user_tz":180,"elapsed":471036,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["print(df_anotado.head())"]},{"cell_type":"markdown","metadata":{"id":"g9uvKZ2tsOnp"},"source":["## OLID BR com Toxicidade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PD0XY9GVGGjV","executionInfo":{"status":"aborted","timestamp":1763671493586,"user_tz":180,"elapsed":471038,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"outputs":[],"source":["df_anotado['is_offensive'] = (df_anotado[tox_cols] >= 0.7).any(axis=1).astype(int)\n","df_anotado.head()\n","\n","print(\"Iniciando experimento -------------------\")\n","experimento(df_anotado, algoritmo=algoritmo, tox_cols=tox_cols, tox_score='doug_tox_sexism_score', min_val=0, max_val=1, n_bins=10, label1=\"toxico1\", label2=\"toxico2\", label3=\"toxico3\")"]},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","folder_path = '/content/drive/MyDrive/red_pill_analises/data_base/dados_anotados/'\n","tox_score = 'toxicity'\n","\n","print(\"Lendo anotações -----------------------------------------\")\n","df_ground_truth = pd.read_csv(folder_path + 'anotacoes_completas.csv', encoding='utf-8')"],"metadata":{"id":"HDL-PR5ZKUog","executionInfo":{"status":"aborted","timestamp":1763671493587,"user_tz":180,"elapsed":471039,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Avaliação Misoginia"],"metadata":{"id":"QIJVhWs0OuyA"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import cohen_kappa_score\n","from statsmodels.stats.inter_rater import fleiss_kappa\n","\n","# Preencher NaNs com 0\n","df_ground_truth[['misoginia1', 'misoginia2', 'misoginia3']] = df_ground_truth[['misoginia1', 'misoginia2', 'misoginia3']].fillna(0)\n","\n","# ===== Cálculo do Kappa de Cohen entre pares =====\n","kappa_1_2 = cohen_kappa_score(df_ground_truth['misoginia1'], df_ground_truth['misoginia2'])\n","kappa_1_3 = cohen_kappa_score(df_ground_truth['misoginia1'], df_ground_truth['misoginia3'])\n","kappa_2_3 = cohen_kappa_score(df_ground_truth['misoginia2'], df_ground_truth['misoginia3'])\n","\n","print(\"Kappa (Misoginia 1 vs 2):\", kappa_1_2)\n","print(\"Kappa (Misoginia 1 vs 3):\", kappa_1_3)\n","print(\"Kappa (Misoginia 2 vs 3):\", kappa_2_3)\n","\n","# ===== Cálculo do número de textos com consenso total =====\n","df_ground_truth['consenso_total'] = (\n","    (df_ground_truth['misoginia1'] == df_ground_truth['misoginia2']) &\n","    (df_ground_truth['misoginia1'] == df_ground_truth['misoginia3'])\n",")\n","quantidade_consenso = df_ground_truth['consenso_total'].sum()\n","print(\"Textos com consenso total:\", quantidade_consenso)\n","\n","# ===== Fleiss' Kappa =====\n","# Supondo que os rótulos possíveis sejam 0 e 1\n","labels = [0, 1]\n","matriz_contagem = []\n","\n","for _, row in df_ground_truth[['misoginia1', 'misoginia2', 'misoginia3']].iterrows():\n","    contagem = [list(row).count(label) for label in labels]\n","    matriz_contagem.append(contagem)\n","\n","matriz_contagem = np.array(matriz_contagem)\n","fleiss = fleiss_kappa(matriz_contagem, method='fleiss')\n","print(\"Fleiss' Kappa:\", fleiss)\n"],"metadata":{"id":"A77o2xR-OwYc","executionInfo":{"status":"aborted","timestamp":1763671493589,"user_tz":180,"elapsed":471040,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_ground_truth['consenso_total'] = (\n","    (df_ground_truth['misoginia1'] == df_ground_truth['misoginia2']) &\n","    (df_ground_truth['misoginia1'] == df_ground_truth['misoginia3'])\n",")\n","\n","quantidade_consenso = df_ground_truth['consenso_total'].sum()\n","print(\"Textos com consenso total:\", quantidade_consenso)"],"metadata":{"id":"KnZQwOVWLfZm","executionInfo":{"status":"aborted","timestamp":1763671493716,"user_tz":180,"elapsed":471167,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Avaliação Misoginia"],"metadata":{"id":"q_XMU2L0PZes"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import cohen_kappa_score\n","from statsmodels.stats.inter_rater import fleiss_kappa\n","\n","# Preencher NaNs com 0\n","df_ground_truth[['toxico1', 'toxico2', 'toxico3']] = df_ground_truth[['toxico1', 'toxico2', 'toxico3']].fillna(0)\n","\n","# ===== Cálculo do Kappa de Cohen entre pares =====\n","kappa_1_2 = cohen_kappa_score(df_ground_truth['toxico1'], df_ground_truth['toxico2'])\n","kappa_1_3 = cohen_kappa_score(df_ground_truth['toxico1'], df_ground_truth['toxico3'])\n","kappa_2_3 = cohen_kappa_score(df_ground_truth['toxico2'], df_ground_truth['toxico3'])\n","\n","print(\"Kappa (toxico 1 vs 2):\", kappa_1_2)\n","print(\"Kappa (toxico 1 vs 3):\", kappa_1_3)\n","print(\"Kappa (toxico 2 vs 3):\", kappa_2_3)\n","\n","# ===== Cálculo do número de textos com consenso total =====\n","df_ground_truth['consenso_total'] = (\n","    (df_ground_truth['toxico1'] == df_ground_truth['toxico2']) &\n","    (df_ground_truth['toxico1'] == df_ground_truth['toxico3'])\n",")\n","quantidade_consenso = df_ground_truth['consenso_total'].sum()\n","print(\"Textos com consenso total:\", quantidade_consenso)\n","\n","# ===== Fleiss' Kappa =====\n","# Supondo que os rótulos possíveis sejam 0 e 1\n","labels = [0, 1]\n","matriz_contagem = []\n","\n","for _, row in df_ground_truth[['toxico1', 'toxico2', 'toxico3']].iterrows():\n","    contagem = [list(row).count(label) for label in labels]\n","    matriz_contagem.append(contagem)\n","\n","matriz_contagem = np.array(matriz_contagem)\n","fleiss = fleiss_kappa(matriz_contagem, method='fleiss')\n","print(\"Fleiss' Kappa:\", fleiss)\n"],"metadata":{"id":"D3aYMZcDPa2r","executionInfo":{"status":"aborted","timestamp":1763671493719,"user_tz":180,"elapsed":471170,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_ground_truth['consenso_total'] = (\n","    (df_ground_truth['toxico1'] == df_ground_truth['toxico2']) &\n","    (df_ground_truth['toxico1'] == df_ground_truth['toxico3'])\n",")\n","\n","quantidade_consenso = df_ground_truth['consenso_total'].sum()\n","print(\"Textos com consenso total:\", quantidade_consenso)"],"metadata":{"id":"cw1ytW4dOZGs","executionInfo":{"status":"aborted","timestamp":1763671493722,"user_tz":180,"elapsed":471172,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from scipy.stats import spearmanr\n","\n","# Exemplo: carregando DataFrame\n","# dg_ground_truth = pd.read_csv(\"seus_dados.csv\")\n","\n","# Calcula correlação\n","corr, p_value = spearmanr(dg_ground_truth['is_toxico'], dg_ground_truth['is_misogino'])\n","\n","print(f\"Correlação de Spearman: {corr:.4f}\")\n","print(f\"p-valor: {p_value:.4f}\")"],"metadata":{"id":"yg51Xdi5kvhP","executionInfo":{"status":"aborted","timestamp":1763671493738,"user_tz":180,"elapsed":471188,"user":{"displayName":"Amanda Fernandes","userId":"14529623761306012468"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4cdbbe5a2310468892f7e234e55a30af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_668f6956ca0340cc9f12ff8803a4f21b","IPY_MODEL_e19f936d353a4c52aa0ec7594f362853","IPY_MODEL_33ec3de1df8548d9b6ed01194a119385"],"layout":"IPY_MODEL_b8e204342f774f90b3df21dd3bcfe8da"}},"668f6956ca0340cc9f12ff8803a4f21b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58d2560ec2d7413c8afb5c2ad7f4a1d9","placeholder":"​","style":"IPY_MODEL_437f131a684f4c5dbd24c479b3e8ecc8","value":"config.json: 100%"}},"e19f936d353a4c52aa0ec7594f362853":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_162393fcd43d4a88b19c0359eef46f2f","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_470f5f213c604d9f83ba273e8411a4ee","value":615}},"33ec3de1df8548d9b6ed01194a119385":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ec95682eb5e4835bf91a93db198e822","placeholder":"​","style":"IPY_MODEL_2b1b581391804ad49e99f63fc491805d","value":" 615/615 [00:00&lt;00:00, 58.4kB/s]"}},"b8e204342f774f90b3df21dd3bcfe8da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d2560ec2d7413c8afb5c2ad7f4a1d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"437f131a684f4c5dbd24c479b3e8ecc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"162393fcd43d4a88b19c0359eef46f2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"470f5f213c604d9f83ba273e8411a4ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ec95682eb5e4835bf91a93db198e822":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b1b581391804ad49e99f63fc491805d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c94f1927f5414d6db6d652cd24cd8487":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c88f86a013684500a6085b9576666b2d","IPY_MODEL_c39ea4df8c5147249c9e685ab5d72329","IPY_MODEL_8e9647797f974e90ace4785f778a893f"],"layout":"IPY_MODEL_8de3545406064d05aa2e7f4c2eae7b24"}},"c88f86a013684500a6085b9576666b2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8874c2912e2b456ba28554b2fdc5d81b","placeholder":"​","style":"IPY_MODEL_66f426ebc3c84278a857060d2af65c61","value":"tokenizer_config.json: 100%"}},"c39ea4df8c5147249c9e685ab5d72329":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b66e73a36de46cea9696a2d6038b15e","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0c21ac39e9543a2beaae11edd066df2","value":25}},"8e9647797f974e90ace4785f778a893f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d956c3c53764a4299c6f65c857bf596","placeholder":"​","style":"IPY_MODEL_d2b26ebcd3fd46e58e6c7790a475ae06","value":" 25.0/25.0 [00:00&lt;00:00, 2.88kB/s]"}},"8de3545406064d05aa2e7f4c2eae7b24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8874c2912e2b456ba28554b2fdc5d81b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66f426ebc3c84278a857060d2af65c61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b66e73a36de46cea9696a2d6038b15e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0c21ac39e9543a2beaae11edd066df2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d956c3c53764a4299c6f65c857bf596":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2b26ebcd3fd46e58e6c7790a475ae06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e12042a7093b4d5eb6835c9ec2280e6d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9465ffbb617c4e6081d21315e9c94670","IPY_MODEL_66ff3f78bcda463e9b439bdf7548226f","IPY_MODEL_ae26a033e07643d6b6cfb87ebd59349e"],"layout":"IPY_MODEL_4948e011443f4d2aa8e6a33a50f46231"}},"9465ffbb617c4e6081d21315e9c94670":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47e6dc9a570b47fd8578bf8e44bdfb4b","placeholder":"​","style":"IPY_MODEL_1f98ebbdbc3b4b66b27aea94cae6a4a5","value":"sentencepiece.bpe.model: 100%"}},"66ff3f78bcda463e9b439bdf7548226f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e18a973e097443c69726c5c832f39d9f","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_947e3eab2303426ca0ff8d851618ba47","value":5069051}},"ae26a033e07643d6b6cfb87ebd59349e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_858aedcf490e47d7a06b25bc7c3ad67c","placeholder":"​","style":"IPY_MODEL_f79cf810b5804e90a436beae2c8649d7","value":" 5.07M/5.07M [00:00&lt;00:00, 25.3MB/s]"}},"4948e011443f4d2aa8e6a33a50f46231":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47e6dc9a570b47fd8578bf8e44bdfb4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f98ebbdbc3b4b66b27aea94cae6a4a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e18a973e097443c69726c5c832f39d9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"947e3eab2303426ca0ff8d851618ba47":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"858aedcf490e47d7a06b25bc7c3ad67c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f79cf810b5804e90a436beae2c8649d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24ae152ec0cc4b74b2eda3ff9124f13c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01fd22d60abd4d12ba08c4e7a0539ea9","IPY_MODEL_7afcbcce496d47aa9fbd7f917ffcf5f5","IPY_MODEL_d6d83997d77e4983a4bbbb29fd82fd0c"],"layout":"IPY_MODEL_887a6b76695b4ac7a5fe554c52f3c433"}},"01fd22d60abd4d12ba08c4e7a0539ea9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43e55e132512423b8edeb7422bc0cd51","placeholder":"​","style":"IPY_MODEL_fa074255b8fc4b52a07113d969cb2128","value":"tokenizer.json: 100%"}},"7afcbcce496d47aa9fbd7f917ffcf5f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_700654ea81dd418683b4f6b627305ba7","max":9096718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5faae99a9d5a45eab2f7e92ed6fb3a51","value":9096718}},"d6d83997d77e4983a4bbbb29fd82fd0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13ee8cd2d466466a8bbf4e7aceb6ca8b","placeholder":"​","style":"IPY_MODEL_f5e7de55e4874021963d619cd72455bf","value":" 9.10M/9.10M [00:00&lt;00:00, 20.0MB/s]"}},"887a6b76695b4ac7a5fe554c52f3c433":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43e55e132512423b8edeb7422bc0cd51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa074255b8fc4b52a07113d969cb2128":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"700654ea81dd418683b4f6b627305ba7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5faae99a9d5a45eab2f7e92ed6fb3a51":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"13ee8cd2d466466a8bbf4e7aceb6ca8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5e7de55e4874021963d619cd72455bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}